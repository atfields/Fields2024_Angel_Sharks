##Script used for analyzing SNP.TRS.F10.gen file produced on the Angel shark reads for 2 ATF indices##

cd /home/afields/Workspace/Angels/analysis/Aug2020

#Loading Libraries
{```{R}```
library('devtools')
library('pegas')
library('adegenet')
library('vcfR') 
library('rospca')
library('dartR')
library('zvau')
library('geosphere')
library('stringr')
library('ggmap')
library('ggcompoplot')
library('vegan')
library('spdep')
library('adespatial')
library('igraph')
library('poppr') 
library('smatr')
library('radiator')
library('related')
library('ggcompoplot')
library('scales')
}

#Add functions
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
} #http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/

}}

outliers <- function(x,z){
   lims <- mean(x) + c(-1, 1) * z * sd(x)     # find loadings +/-z sd from mean loading
   x[x < lims[1] | x > lims[2]]               # locus names in these tails
 }

Locus_hunt <- function(GEN, DAPC, THRES=0.8, GROUP="~POP", AXIS=1, ALPHA=0.05, MIN=0.5){
#Objects to put into the function

#GEN <- The genind object used to make a DAPC
#DAPC <- The DAPC oject made from the genind object
#THRES <- The precent of loci to remove during the 1st round
#GROUP <- The strata group that should be used
#AXIS <- The axis you would like to search along
#ALPHA <- The significance value you would like to work with 
#MIN <- The lower limit that the threshold can approach, but never reach

#Fills in missing values
if(missing(THRES)){THRES=0.8}
if(missing(GROUP)){GROUP="~POP"}
if(missing(AXIS)){AXIS=1}
if(missing(ALPHA)){ALPHA=0.5}
if(missing(MIN)){MIN=0.5}

# Sets up the varibles tested
GOOD <- as.vector(MIN)
BAD <- as.vector(1)
if(THRES<=MIN){THRES <- MIN + 0.05}
if(THRES>=0.9975){THRES <- 0.95}

# Loop to look for optimal value
while(abs(THRES-max(GOOD))>0.001){
if(length(GOOD)>20){cat(paste("Threshold not found\nPlease try a new starting point\nBest Threshold tried was",max(GOOD),"\n")); break}
print(paste("Processing threshold", THRES))
# Getting the loci to test
contrib <- rownames(DAPC$var.contr)[which(DAPC$var.contr[,AXIS] > quantile(DAPC$var.contr[,AXIS], prob=THRES))]
pc.loci <- unique(matrix(unlist(strsplit(contrib, "[.]")),ncol=2,byrow=T)[,1])

# Select out the data sets
set.loc<-locNames(GEN)[which(!(locNames(GEN) %in% pc.loci))]
tmp.keep<-GEN[, loc=set.loc]
set.loc<-locNames(GEN)[which((locNames(GEN) %in% pc.loci))]
tmp.rm<-GEN[, loc=set.loc]

# Attribute Variance
tmp.keep.result <- poppr.amova(tmp.keep, as.formula(GROUP), quiet=T)
tmp.rm.result <- poppr.amova(tmp.rm, as.formula(GROUP), quiet=T)

# Test for significance
tmp.keep.test <- randtest(tmp.keep.result)
tmp.rm.test <- randtest(tmp.rm.result)

#Tables for comparison
tmp.ktable <- data.frame(cbind(tmp.keep.test$names, tmp.keep.test$pvalue),row.names=1)
names(tmp.ktable) <- "Kept"
tmp.rtable <- data.frame(cbind(tmp.rm.test$names, tmp.rm.test$pvalue),row.names=1)
names(tmp.rtable) <- "Removed"
print(cbind(tmp.ktable, tmp.rtable))

#Decision of what to do next
if(as.numeric(as.matrix(tmp.ktable[nrow(tmp.ktable),1])) < ALPHA |	as.numeric(as.matrix(tmp.rtable[nrow(tmp.rtable),1])) > ALPHA){
	BAD <- c(BAD, THRES)
} else if(as.numeric(as.matrix(tmp.ktable[nrow(tmp.ktable),1])) > ALPHA | as.numeric(as.matrix(tmp.rtable[nrow(tmp.rtable),1])) < ALPHA){
	GOOD <- c(GOOD, THRES)
	STORE.GOOD.gen.keep <- tmp.keep
	STORE.GOOD.gen.rm <- tmp.rm
	STORE.GOOD.tab.keep <- tmp.ktable
	STORE.GOOD.tab.rm <- tmp.rtable
}
THRES <- mean(c(max(GOOD),min(BAD)))

}
THRES <- max(GOOD)

#Outputs
OUTPUT.list <- list()
OUTPUT.list[[1]] <- STORE.GOOD.gen.keep
OUTPUT.list[[2]] <- STORE.GOOD.gen.rm
OUTPUT.list[[3]] <- paste("The Best Threshold tested was ", max(GOOD), "\nThis removed ", length(locNames(STORE.GOOD.gen.rm)), " loci (", round(length(locNames(STORE.GOOD.gen.rm))/length(locNames(GEN)),3)*100,"%)\n",
"Kept p-value is ", STORE.GOOD.tab.keep[nrow(STORE.GOOD.tab.keep),1], "\nRemoved p-value is ", STORE.GOOD.tab.rm[nrow(STORE.GOOD.tab.rm),1], "\nData has been output to the 1st two objects of this list\n Item 1 contains the kept genind object\n Item 2 contains the removed genind object\n", sep="")
return(OUTPUT.list)
}

}}}}}}}}}}}}}}}}}}}#Cleanup

#Analyzing data
#Importing Data
{```{R}```
strata <- read.csv(file = "SNP.TRS.F10.2020-09-25/indv.csv", header = TRUE)

vcf<-read.vcfR(file="haplotyping/SNP.TRS.F10.vcf")
gen.vcf<-vcfR2genind(vcf)
strata(gen.vcf) <- strata[match(indNames(gen.vcf),strata$INDV),]
head(strata(gen.vcf))
rm(vcf)

gen <- read.genepop(file = "haplotyping/SNP.TRS.F10.gen", ncode=3L, quiet = FALSE)
strata(gen) <- strata[match(indNames(gen),strata$INDV),]
head(strata(gen))

gen@other$lat<-gen@strata[,c("Lon","Lat")]
gen@other$lat[,1]<-as.numeric(as.character(gen@strata$Lon))
gen@other$lat[,2]<-as.numeric(as.character(gen@strata$Lat))	#As numeric
gen@other$xy<-gen@strata[,c("Lon","Lat")]	#As factor

#Adding related ID to strata
gen.indv <- substr(gen@strata$INDV, 1, 20)
gen.indv <- gsub("_","-",gen.indv)
gen.indv <- data.frame(cbind(as.character(gen@strata$INDV), gen.indv))
names(gen.indv) <- c("gen.ID", "relate.ID")

gen@strata$relate.ID <- gen.indv[match(indNames(gen),gen.indv$gen.ID),"relate.ID"]
head(strata(gen))
}

#Setting color schemes
{```{R}```
#           "Atl"   "EAST"    "Pac"     "WEST"
col.All<-c("red4","dodgerblue","grey50","mediumblue")

c2 <- c("mediumblue", "red4")
c3 <- c("dodgerblue", "red4", "mediumblue")
c4 <- c("lightslateblue", "mediumblue", "red4", "dodgerblue")
c5 <- c("dodgerblue", "mediumblue", "royalblue1", "lightslateblue", "red4")
c6 <- c("mediumblue", "lightslateblue", "royalblue1", "red4","cornflowerblue", "dodgerblue")

}

#PCA of raw data
{```{R}```
#Standard
X <- scaleGen(gen, NA.method="mean", scale=F)
pca1 <- dudi.pca(X,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)
setPop(gen)<-~POP
ade4::s.class(pca1$li, pop(gen), col=col.All, cstar=0)

tiff("PCA_POP_raw_all_loci.tif", res=300, height =2000, width=2000)
ade4::s.class(pca1$li, pop(gen), col=col.All, cstar=0)
dev.off()
}

#Removing duplates
{```{R}```
remove.ind <- c("Atl.AS.124_Lib1_I12_D05", "EAST.AS.9.2_Lib1_I12_D04")
set.ind <- subset(indNames(gen), !indNames(gen) %in% remove.ind)

gen2 <- gen[set.ind, ]
gen2.vcf <- gen.vcf[set.ind, ]
}

#Looking for rough relatedness between individuals
{```{R}```
test.cov <- genomic_converter(gen, output = "related", parallel.core=20)
test.out <- coancestry(test.cov$related , dyadml =1)
}

#Removing duplicates based upon relatedness
#Removing 1 of those which have a relationship value larger than 1
{```{R}```
dups.rel <- test.out$relatedness[test.out$relatedness$dyadml>1,2:3]
dups.rel
#                 ind1.id              ind2.id
#650 Atl.AS.124-Lib1-I12- Atl.AS.124.-Lib2-I12

strata(gen)[grep("Atl.AS.124",strata(gen)[,1]),]
# Atl.AS.124_Lib1_I12_D05 is the right one to remove

}}}}}

#Exploring relationship data
{```{R}```
#What is the overall relationship spread in the samples
par(mfrow=c(3,1))
hist(test.out$relatedness$dyadml, breaks=200, main="All Relationships", col="red4")
hist(test.out$relatedness$dyadml, breaks=200, main="All Relationships", ylim=c(0,100), col="red4")
hist(test.out$relatedness$dyadml, breaks=200, main="All Relationships", ylim=c(0,10), col="red4")

#Pulling data within populations from related output
MAX <- vector()
for(i in c("Atl", "EAST", "WEST")){
tmp.pop <- gen@strata[gen@strata$POP==i,"relate.ID"]
tmp.dyadml <- test.out$relatedness$dyadml[test.out$relatedness$ind1.id %in% tmp.pop & test.out$relatedness$ind2.id %in% tmp.pop]
MAX <- max(MAX,tmp.dyadml)
assign(paste(i,"dyadml",sep="_"),tmp.dyadml)
}

#Making histograms of within population data from each location
tiff("Angels_within_relatedness.tiff", res=200, height=6000, width=2000)
par(mfrow=c(3,1))
for(i in c("Atl", "EAST", "WEST")){
hist(get(paste(i,"dyadml",sep="_")),breaks=50,xlim=c(0,MAX*1.01), main=i, col="green4", xlab=NULL)
}
dev.off()

#Pulling data between populations from related output
MAX <- vector()
for(i in c("Atl", "EAST", "WEST")){
tmp.pop <- gen@strata[gen@strata$POP==i,"relate.ID"]
tmp.dyadml <- test.out$relatedness$dyadml[!(test.out$relatedness$ind1.id %in% tmp.pop) & test.out$relatedness$ind2.id %in% tmp.pop | test.out$relatedness$ind1.id %in% tmp.pop & !(test.out$relatedness$ind2.id %in% tmp.pop)]
MAX <- max(MAX,tmp.dyadml)
assign(paste(i,"out_dyadml",sep="_"),tmp.dyadml)
}

#Making histograms of between population data from each location
tiff("Angels_between_relatedness.tiff", res=200, height=6000, width=2000)
par(mfrow=c(3,1))
for(i in c("Atl", "EAST", "WEST")){
hist(get(paste(i,"out_dyadml",sep="_")),breaks=50,xlim=c(0,MAX*1.01), main=i, col="green4", xlab=NULL)
}
dev.off()

}

#Looking at those which have a relationship value larger than 0.2
{```{R}```
#Looking for the relationship between high related values
test.out$relatedness[test.out$relatedness$dyadml>0.5,c(2:3,11)]
#Both are duplicates with a sample removed in gen2
}

#PCA with Pacific sample
{```{R}```
#Standard
X <- scaleGen(gen2, NA.method="mean", scale=F)
pca1 <- dudi.pca(X,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)
setPop(gen2)<-~POP
par(mfrow=c(1,1))
ade4::s.class(pca1$li, pop(gen2), col=col.All, cstar=0, axesell=F, clabel=0)
mtext(paste("x-axis variation: ",format(round(100*pca1$eig[1]/sum(pca1$eig),3),nsmall=3),"%",sep=""),1, line=0.8, adj=0.15, cex=1.5)
mtext(paste("y-axis variation: ",format(round(100*pca1$eig[2]/sum(pca1$eig),3),nsmall=3),"%",sep=""),1, line=2, adj=0.15, cex=1.5)
legend(x=-25.5, y=-22,legend=c("Atlantic (n=17)", "East GOM (n=25)", "West GOM (n=20)", "Pacific (n=1)"),col=c("red4","dodgerblue", "mediumblue","grey50"), cex=1.5, pch=16, bty="n", ncol=1)

tiff("PCA_POP_all_loci.tif", res=300, height =2000, width=2000)
ade4::s.class(pca1$li, pop(gen2), col=col.All, cstar=0, axesell=F, clabel=0)
mtext(paste("x-axis variation: ",format(round(100*pca1$eig[1]/sum(pca1$eig),3),nsmall=3),"%",sep=""),1, line=0.8, adj=0.15, cex=1.5)
mtext(paste("y-axis variation: ",format(round(100*pca1$eig[2]/sum(pca1$eig),3),nsmall=3),"%",sep=""),1, line=2, adj=0.15, cex=1.5)
legend(x=-25.5, y=-22,legend=c("Atlantic (n=17)", "East GOM (n=25)", "West GOM (n=20)", "Pacific (n=1)"),col=c("red4","dodgerblue", "mediumblue","grey50"), cex=1.5, pch=16, bty="n", ncol=1)
dev.off()
}

#Removing Pacific sample
{```{R}```
remove.ind <- c("Atl.AS.124_Lib1_I12_D05", "EAST.AS.9.2_Lib1_I12_D04", "Pac.AS.T437_Lib2_I12_D01")
set.ind <- subset(indNames(gen), !indNames(gen) %in% remove.ind)

gen2 <- gen[set.ind, ]
gen2.vcf <- gen.vcf[set.ind, ]
}

#PCAs without Pacific sample
{```{R}```
#Standard
X <- scaleGen(gen2, NA.method="mean", scale=F)
pca1 <- dudi.pca(X,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)
setPop(gen2)<-~POP
par(mfrow=c(1,1))
ade4::s.class(pca1$li, pop(gen2), col=col.All, cstar=0, axesell=F, clabel=0)
mtext(paste("x-axis variation: ",format(round(100*pca1$eig[1]/sum(pca1$eig),3),nsmall=3),"%",sep=""),1, line=0.8, adj=0.15, cex=1.5)
mtext(paste("y-axis variation: ",format(round(100*pca1$eig[2]/sum(pca1$eig),3),nsmall=3),"%",sep=""),1, line=2, adj=0.15, cex=1.5)
legend(x=-25.5, y=-22,legend=c("Atlantic (n=17)", "East GOM (n=25)", "West GOM (n=20)", "Pacific (n=1)"),col=c("red4","dodgerblue", "mediumblue","grey50"), cex=1.5, pch=16, bty="n", ncol=1)

tiff("PCA_NWA_POP_all_loci.tif", res=300, height =2000, width=2000)
ade4::s.class(pca1$li, pop(gen2), col=col.All, cstar=0, axesell=F, clabel=0)
mtext(paste("x-axis variation: ",format(round(100*pca1$eig[1]/sum(pca1$eig),3),nsmall=3),"%",sep=""),1, line=0.8, adj=0.15, cex=1.5)
mtext(paste("y-axis variation: ",format(round(100*pca1$eig[2]/sum(pca1$eig),3),nsmall=3),"%",sep=""),1, line=2, adj=0.15, cex=1.5)
legend(x=-25.5, y=-22,legend=c("Atlantic (n=17)", "East GOM (n=25)", "West GOM (n=20)", "Pacific (n=1)"),col=c("red4","dodgerblue", "mediumblue","grey50"), cex=1.5, pch=16, bty="n", ncol=1)
dev.off()

#Robust
X <- scaleGen(gen2, NA.method="mean", center=F, scale=F)
gen.rob<-robpca(X, 0, kmax=1000, alpha=0.5, stand=F, ndir=5000)
diagPlot(gen.rob)

tiff("robPCA_NWA_POP_all_loci.tif", res=300, height =2000, width=2000)
diagPlot(gen.rob)
dev.off()
}

#Library Bias (Outflank)
{```{R}```
setPop(gen2.vcf)<-~Lib/POP
tmp<-gl.outflank(gen2.vcf, qthreshold = 0.1)	#Can use plot=F option if you want
length(which(tmp$outflank$results[15]=="TRUE"))	#360

outliers<-tmp$outflank$results[which(tmp$outflank$results[15]=="TRUE"),1]
out.list<-dput(matrix(unlist(strsplit(as.vector(outliers),"[.]")),ncol=2,byrow=T)[,1])
tmp<-matrix(unlist(strsplit(as.vector(out.list),"[_]")),ncol=4,byrow=T)
#head(tmp)
out.list<-unique(paste(tmp[,1],tmp[,2],tmp[,3],sep="_"))
length(out.list) #97
gen.out.list<-(out.list)

set.loc<-locNames(gen2)[which(!(locNames(gen2) %in% gen.out.list))]
gen.net<-gen2[, loc=set.loc]
set.loc<-locNames(gen2)[which((locNames(gen2) %in% gen.out.list))]
gen.out<-gen2[, loc=set.loc]

X <- scaleGen(gen2, NA.method="mean", scale=F)
pca1 <- dudi.pca(X,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

X.net <- scaleGen(gen.net, NA.method="mean", scale=F)
pca.net <- dudi.pca(X.net,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

X.out <- scaleGen(gen.out, NA.method="mean", scale=F)
pca.out <- dudi.pca(X.out,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

setPop(gen2) <- setPop(gen.net) <- setPop(gen.out) <- ~POP
par(mfrow=c(3,1))
ade4::s.class(pca1$li, pop(gen2), col=col.All, cstar=0, axesell=F)
mtext(paste("All data (n=",length(locNames(gen2))," loci)", sep=""), 3, 2, adj = 0.95)
ade4::s.class(pca.net$li, pop(gen.net), col=col.All, cstar=0, axesell=F)
mtext(paste("Neutral data (n=",length(locNames(gen.net))," loci)", sep=""), 3, 2, adj = 0.95)
ade4::s.class(pca.out$li, pop(gen.out), col=col.All, cstar=0, axesell=F)
mtext(paste("Outlier data (n=",length(locNames(gen.out))," loci)", sep=""), 3, 2, adj = 0.95)

setPop(gen2) <- setPop(gen.net) <- setPop(gen.out) <- ~Lib/POP
par(mfrow=c(3,1))
ade4::s.class(pca1$li, pop(gen2), col=col.All, cstar=0, axesell=F)
mtext(paste("All data (n=",length(locNames(gen2))," loci)", sep=""), 3, 2, adj = 0.95)
ade4::s.class(pca.net$li, pop(gen.net), col=col.All, cstar=0, axesell=F)
mtext(paste("Neutral data (n=",length(locNames(gen.net))," loci)", sep=""), 3, 2, adj = 0.95)
ade4::s.class(pca.out$li, pop(gen.out), col=col.All, cstar=0, axesell=F)
mtext(paste("Outlier data (n=",length(locNames(gen.out))," loci)", sep=""), 3, 2, adj = 0.95)

write.table(gen.out.list, "Outflank_Library_Outliers.list", quote=F, col.names=F, row.names=F)

gen3 <- gen.net

tmp<-vector()
for(i in gen.out.list){
tmp <- append(tmp,grep(i, locNames(gen2.vcf), fixed=F, value=T))
}

set.loc<-subset(locNames(gen2.vcf), !locNames(gen2.vcf) %in% tmp)

gen3.vcf<-gen2.vcf[ ,loc=set.loc]
}

#Library Bias (Bayescan)
{```{R}```
setPop(gen2)<-~Lib/POP
writeGenPop(gen3, "SNP.TRS.Lib_all.gen", "NWA Angel shark data without dups by Library")

#Converting to BS format
```{bash}```
java -jar /usr/local/bin/PGDSpider2.1.1.3-cli.jar -inputfile SNP.TRS.Lib_all.gen -inputformat GENEPOP -outputfile SNP.TRS.Lib_all.BS -outputformat BAYESCAN -spid /home/afields/bin/genepop_to_BS.spid

#Running Bayescan
bayescan_2.1 SNP.TRS.Lib_all.BS -od ./Bayescan -all-trace -threads 20 -thin 100 -nbp 30 -pr_odds 100

#Analyzing results
head -n2 ../SNP.TRS.Lib_all.gen | tail -n 1 | sed 's/, /\n/g' > contigs
echo "Contigs" | cat - contigs > tmp; mv tmp contigs
paste contigs SNP.TRS.Lib_al_fst.txt | awk '{$2=""; print}' > fst.txt

awk 'NR==1{next;} $5>0.05{print $0}' fst.txt | wc -l
awk 'NR==1{next;} $5>0.05{print $0}' fst.txt | less
awk 'NR==1{next;} $5>0.05{print $1}' fst.txt | sort > Bayescan_Outliers_Lib.list
}

#Looking at effects of Bayescan outliers
{```{R}```
tmp.out <- as.character(as.matrix(read.csv("Bayescan/Bayescan_Outliers_Lib.list", head=F)))

set.loc<-locNames(gen2)[which(!(locNames(gen2) %in% tmp.out))]
gen2.net<-gen2[, loc=set.loc]
set.loc<-locNames(gen2)[which((locNames(gen2) %in% tmp.out))]
gen2.out<-gen2[, loc=set.loc]

X <- scaleGen(gen2, NA.method="mean", scale=F)
pca1 <- dudi.pca(X,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

X.net <- scaleGen(gen2.net, NA.method="mean", scale=F)
pca.net <- dudi.pca(X.net,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

X.out <- scaleGen(gen2.out, NA.method="mean", scale=F)
pca.out <- dudi.pca(X.out,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

setPop(gen2) <- setPop(gen2.net) <- setPop(gen2.out) <- ~POP
par(mfrow=c(3,1))
ade4::s.class(pca1$li, pop(gen2), col=col.All, cstar=0, axesell=F)
mtext(paste("All data (n=",length(locNames(gen2))," loci)", sep=""), 3, 2, adj = 0.95)
ade4::s.class(pca.net$li, pop(gen2.net), col=col.All, cstar=0, axesell=F)
mtext(paste("All data (n=",length(locNames(gen2.net))," loci)", sep=""), 3, 2, adj = 0.95)
ade4::s.class(pca.out$li, pop(gen2.out), col=col.All, cstar=0, axesell=F)
mtext(paste("All data (n=",length(locNames(gen2.out))," loci)", sep=""), 3, 2, adj = 0.95)
}

#Removing Library outliers
{```{R}```
OF.out <- read.table("Outflank_Library_Outliers.list", head=F)
tmp.out <- read.csv("Bayescan/Bayescan_Outliers_Lib.list", head=F)
gen.out.list <- unique(c(as.character(as.matrix(OF.out)), as.character(as.matrix(tmp.out))))
set.loc<-locNames(gen2)[which(!(locNames(gen2) %in% gen.out.list))]
gen3<-gen2[, loc=set.loc]

tmp<-vector()
for(i in gen.out.list){
tmp <- append(tmp,grep(i, locNames(gen2.vcf), fixed=F, value=T))
}

set.loc<-subset(locNames(gen2.vcf), !locNames(gen2.vcf) %in% tmp)
gen3.vcf<-gen2.vcf[ ,loc=set.loc]
}

### NWA Locations ###
#Outlier Detection (Outflank)
{```{R}```
setPop(gen3.vcf)<-~POP
tmp<-gl.outflank(gen3.vcf, qthreshold = 0.1)
length(which(tmp$outflank$results[15]=="TRUE"))
# Returned 0 outliers
}

#Outlier Detection (Bayescan)
{```{R}```
#Exporting data for Bayescan
setPop(gen3)<-~POP
writeGenPop(gen3, "SNP.TRS.Final_all.gen", "NWA Angel shark data without dups by POP")

#Converting to BS format
```{bash}```
java -jar /usr/local/bin/PGDSpider2.1.1.3-cli.jar -inputfile SNP.TRS.Final_all.gen -inputformat GENEPOP -outputfile SNP.TRS.Final_all.BS -outputformat BAYESCAN -spid /home/afields/bin/genepop_to_BS.spid

#Running Bayescan
bayescan_2.1 SNP.TRS.Final_all.BS -od ./Bayescan -all-trace -threads 20 -thin 100 -nbp 30 -pr_odds 100

#Analyzing results
head -n2 ../SNP.TRS.Final_all.gen | tail -n 1 | sed 's/, /\n/g' > contigs
echo "Contigs" | cat - contigs > tmp; mv tmp contigs
paste contigs SNP.TRS.Final_al_fst.txt | awk '{$2=""; print}' > fst.txt

awk 'NR==1{next;} $5>0.05{print $0}' fst.txt | wc -l
# Returned 0 outliers
}

#Looking for monomorphic loci
{```{R}```
mono.list <- names(which(gen3@loc.n.all==1))
length(mono.list)
#2
}

#Splitting outliers
{```{R}```
set.loc<-locNames(gen3)[which(!(locNames(gen3) %in% mono.list))]
gen.net<-gen3[, loc=set.loc]

tmp<-vector()
for(i in mono.list){
tmp <- append(tmp,grep(i, locNames(gen3), fixed=F, value=T))
}

set.loc<-subset(locNames(gen3.vcf), !locNames(gen3.vcf) %in% tmp)
gen.vcf.net<-gen3.vcf[ ,loc=set.loc]
}

##DAPC##
#Neutral loci#
{```{R}```
#Looking at groups
grp <- find.clusters(gen.net,  max.n.clust=10, n.pca=300, method = "ward")		#1
grp <- find.clusters(gen.net,  max.n.clust=10, n.pca=300, method = "kmeans")	#1

grp2 <- find.clusters(gen.net, max.n.clust=40, n.pca=300, n.clust =2, method="kmeans")
grp3 <- find.clusters(gen.net, max.n.clust=40, n.pca=300, n.clust =3, method="kmeans")
grp4 <- find.clusters(gen.net, max.n.clust=40, n.pca=300, n.clust =4, method="kmeans")
grp5 <- find.clusters(gen.net, max.n.clust=40, n.pca=300, n.clust =5, method="kmeans")
grp6 <- find.clusters(gen.net, max.n.clust=40, n.pca=300, n.clust =6, method="kmeans")

setPop(gen.net)<-~POP
table(pop(gen.net), grp2$grp)	#Atl, GOM
table(pop(gen.net), grp3$grp)	#Atl, E GOM, W GOM + 4
table(pop(gen.net), grp4$grp)	#Atl, E GOM (5), E GOM (16), W GOM + 4
table(pop(gen.net), grp5$grp)	#Atl, E GOM (5), E GOM (16), W GOM(8) + 3, W GOM(12) + 1
table(pop(gen.net), grp6$grp)	#Atl, E GOM (5), E GOM (7) + 1, E GOM (9), W GOM(10), W GOM(9) + 4

tmp <- data.frame(grp2$grp)[match(gen.net@strata$INDV,names(grp2$grp)),]
gen.net@strata$G2 <- as.numeric(tmp)
tmp <- data.frame(grp3$grp)[match(gen.net@strata$INDV,names(grp3$grp)),]
gen.net@strata$G3 <- as.numeric(tmp)
tmp <- data.frame(grp4$grp)[match(gen.net@strata$INDV,names(grp4$grp)),]
gen.net@strata$G4 <- as.numeric(tmp)
tmp <- data.frame(grp5$grp)[match(gen.net@strata$INDV,names(grp5$grp)),]
gen.net@strata$G5 <- as.numeric(tmp)
tmp <- data.frame(grp6$grp)[match(gen.net@strata$INDV,names(grp6$grp)),]
gen.net@strata$G6 <- as.numeric(tmp)

write.table(strata(gen.net), "gen.net_strata.txt", col.names=T, row.names=F, quote=F)
}

#Loading strata from saved file
{```{R}```
strata2 <- read.table("gen.net_strata.txt", head=T, sep=" ")
strata(gen3.vcf) <- strata2[match(indNames(gen3.vcf),strata2$INDV),]
head(strata(gen3.vcf))
strata(gen3) <- strata2[match(indNames(gen3),strata2$INDV),]
head(strata(gen3))
strata(gen.net) <- strata2[match(indNames(gen.net),strata2$INDV),]
head(strata(gen.net))
}

#PCAs without Pacific sample
{```{R}```
#Standard
X <- scaleGen(gen.net, NA.method="mean", scale=F)
pca1 <- dudi.pca(X,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)
setPop(gen.net)<-~G3
par(mfrow=c(1,1))
ade4::s.class(pca1$li, pop(gen.net), col=col.All, cstar=0, axesell=F, clabel=0)
mtext(paste("x-axis variation: ",format(round(100*pca1$eig[1]/sum(pca1$eig),3),nsmall=3),"%",sep=""),1, line=0.8, adj=0.15, cex=1)
mtext(paste("y-axis variation: ",format(round(100*pca1$eig[2]/sum(pca1$eig),3),nsmall=3),"%",sep=""),1, line=2, adj=0.15, cex=1)
legend(x=-10, y=9,legend=c(paste("Atlantic (n=",length(which(pop(gen.net)=="2")),")",sep=""), paste("East GOM (n=",length(which(pop(gen.net)=="1")),")",sep=""), paste("West GOM (n=",length(which(pop(gen.net)=="3")),")",sep="")),col=c("red4","dodgerblue","grey50"), cex=1, pch=16, bty="n", ncol=1)

tiff("PCA_NWA_POP_net_loci.tif", res=300, height =2000, width=2000)
ade4::s.class(pca1$li, pop(gen.net), col=col.All, cstar=0, axesell=F, clabel=0)
mtext(paste("x-axis variation: ",format(round(100*pca1$eig[1]/sum(pca1$eig),3),nsmall=3),"%",sep=""),1, line=0.8, adj=0.15, cex=1)
mtext(paste("y-axis variation: ",format(round(100*pca1$eig[2]/sum(pca1$eig),3),nsmall=3),"%",sep=""),1, line=2, adj=0.15, cex=1)
legend(x=-10, y=9,legend=c(paste("Atlantic (n=",length(which(pop(gen.net)=="2")),")",sep=""), paste("East GOM (n=",length(which(pop(gen.net)=="1")),")",sep=""), paste("West GOM (n=",length(which(pop(gen.net)=="3")),")",sep="")),col=c("red4","dodgerblue","grey50"), cex=1, pch=16, bty="n", ncol=1)
dev.off()

#Robust
X <- scaleGen(gen.net, NA.method="mean", center=F, scale=F)
gen.rob<-robpca(X, 0, kmax=1000, alpha=0.5, stand=F, ndir=5000)
diagPlot(gen.rob)

tiff("robPCA_NWA_POP_all_loci.tif", res=300, height =2000, width=2000)
diagPlot(gen.rob)
dev.off()
}

#DAPC Cross validation
{```{R}```
X.net <- scaleGen(gen.net, NA.method="mean", scale=F)

tiff("Xval_grps_net_loci.tif", res=300, height =12000, width=2000)
par(mfrow=c(5,1))
xval.2.net <- xvalDapc(X.net, strata(gen.net)$G2, n.pca.max = 300, training.set = 0.9, result = "groupMean", center = TRUE, scale = FALSE, n.pca = NULL, n.rep = 50, xval.plot = TRUE)
xval.3.net <- xvalDapc(X.net, strata(gen.net)$G3, n.pca.max = 300, training.set = 0.9, result = "groupMean", center = TRUE, scale = FALSE, n.pca = NULL, n.rep = 50, xval.plot = TRUE)
xval.4.net <- xvalDapc(X.net, strata(gen.net)$G4, n.pca.max = 300, training.set = 0.9, result = "groupMean", center = TRUE, scale = FALSE, n.pca = NULL, n.rep = 50, xval.plot = TRUE)
xval.5.net <- xvalDapc(X.net, strata(gen.net)$G5, n.pca.max = 300, training.set = 0.9, result = "groupMean", center = TRUE, scale = FALSE, n.pca = NULL, n.rep = 50, xval.plot = TRUE)
xval.6.net <- xvalDapc(X.net, strata(gen.net)$G6, n.pca.max = 300, training.set = 0.9, result = "groupMean", center = TRUE, scale = FALSE, n.pca = NULL, n.rep = 50, xval.plot = TRUE)
dev.off()

xval.2.net[2:6]	# Success:1			RMSE:0				PCs:45
xval.3.net[2:6]	# Success:1			RMSE:0				PCs:5
xval.4.net[2:6]	# Success:0.9566667	RMSE:0.1013794		PCs:20
xval.5.net[2:6]	# Success:0.9086667	RMSE:0.1349074		PCs:20
xval.6.net[2:6]	# Success:0.9272222	RMSE:0.1025147		PCs:20
}

#Mapping
{```{R}```
tmp<-data.frame(row.names=indNames(gen.net))
tmp$POP<-strata[match(row.names(tmp),strata$INDV),"POP"]
tmp$Lon<-strata[match(row.names(tmp),strata$INDV),"Lon"]
tmp$Lat<-strata[match(row.names(tmp),strata$INDV),"Lat"]
tmp$G2<-grp2$grp[match(row.names(tmp),names(grp2$grp))]
tmp$G4<-grp3$grp[match(row.names(tmp),names(grp3$grp))]
tmp$G4<-grp4$grp[match(row.names(tmp),names(grp4$grp))]
tmp$G5<-grp5$grp[match(row.names(tmp),names(grp5$grp))]
tmp$G6<-grp6$grp[match(row.names(tmp),names(grp6$grp))]

tmp$G3<-strata(gen.net)$G3[match(row.names(tmp),strata(gen.net)$INDV)]
tmp$DAPC1<-xval.3.net$DAPC$ind.coord[match(row.names(tmp),rownames(xval.3.net$DAPC$ind.coord)),1]
tmp$DAPC2<-xval.3.net$DAPC$ind.coord[match(row.names(tmp),rownames(xval.3.net$DAPC$ind.coord)),2]

Gulf_map<-ggmap(get_stamenmap(bbox = c(left = -100, bottom = 24, right =-74, top = 38.3), zoom = 8, maptype=c("terrain-background")))
Gulf_map

p2.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G2, alpha =0.5), data=tmp, shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c2) + theme(legend.position="none") + ggtitle("Ward's 2 groups")
p3.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G3, alpha =0.5), data=tmp, shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c3) + theme(legend.position="none") + ggtitle("k-means 3 groups")
p4.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G4, alpha =0.5), data=tmp, shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c4) + theme(legend.position="none") + ggtitle("Ward's 4 groups")
p5.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G5, alpha =0.5), data=tmp, shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c5) + theme(legend.position="none") + ggtitle("Ward's 5 groups")
p6.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G6, alpha =0.5), data=tmp, shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c6) + theme(legend.position="none") + ggtitle("Ward's 6 groups")

p2.map
p3.map
p4.map
p5.map
p6.map

multiplot(p2.map, p3.map, p4.map, p5.map, p6.map, cols=2)

p3.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G3, alpha =0.5), data=tmp, shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c3[c(2,1,3)]) + theme(legend.position="none") + ggtitle("Kmeans=3 groups")
p3.1.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G3, alpha =0.5), data=subset(tmp, G3==1), shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c3[1]) + theme(legend.position="none") + ggtitle("Kmeans=3: East Gulf group")
p3.2.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G3, alpha =0.5), data=subset(tmp, G3==2), shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c3[2]) + theme(legend.position="none") + ggtitle("Kmeans=3: Atlantic group")
p3.3.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G3, alpha =0.5), data=subset(tmp, G3==3), shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c3[3]) + theme(legend.position="none") + ggtitle("Kmeans=3: West Gulf group")

multiplot(p3.map, p3.1.map, p3.2.map, p3.3.map, cols=2)

p4.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G4, alpha =0.5), data=tmp, shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c4) + theme(legend.position="none") + ggtitle("Kmeans=4 groups")
p4.1.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G4, alpha =0.5), data=subset(tmp, G4==1), shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c4[1]) + theme(legend.position="none") + ggtitle("Kmeans=4: East Gulf group 1")
p4.2.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G4, alpha =0.5), data=subset(tmp, G4==2), shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c4[2]) + theme(legend.position="none") + ggtitle("Kmeans=4: West Gulf group")
p4.3.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G4, alpha =0.5), data=subset(tmp, G4==3), shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c4[3]) + theme(legend.position="none") + ggtitle("Kmeans=4: Atlantic group")
p4.4.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G4, alpha =0.5), data=subset(tmp, G4==4), shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c4[4]) + theme(legend.position="none") + ggtitle("Kmeans=4: East Gulf group 2")

multiplot(p4.3.map, p4.1.map, p4.2.map, p4.4.map, cols=2)

ggsave("Angel_Shark_kmeans_clustaring_maps_neutral.tif",multiplot(p2.map, p3.map, p4.map), device="tiff")
ggsave("Angel_Shark_kmeans_clustaring_maps3_neutral.tif",multiplot(p3.map, p3.1.map, p3.2.map, p3.3.map, cols=2), device="tiff")
ggsave("Angel_Shark_kmeans_clustaring_maps4_neutral.tif",multiplot(p4.3.map, p4.1.map, p4.2.map, p4.4.map, cols=2), device="tiff")

#ggsave("Map_DAPC_2POP.tif",p2.map,device="tiff")
#ggsave("Map_DAPC_3POP.tif",p3.map,device="tiff")
#ggsave("Map_DAPC_4POP.tif",p4.map,device="tiff")
#ggsave("Map_DAPC_5POP.tif",p5.map,device="tiff")
#ggsave("Map_DAPC_6POP.tif",p6.map,device="tiff")

### Looking for if there is any indication of association difference to distance around the Gulf break ###
#Average between the location of all the Gulf samples in the DAPC
mean(xval.3.net$DAPC$ind.coord[which(xval.3.net$DAPC$grp==1 | xval.3.net$DAPC$grp==3),2])

#Putting all the points on a map with a gradient of colors across them
p3.DAPC2.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = DAPC2, alpha = 1), data=tmp, shape=21, color="black", stroke=0.1, size =2.5) + 
 scale_fill_gradient2(low = "red4", mid="palegreen" ,high = "mediumblue", midpoint=-0.2945437) + 
 theme(legend.position="none") + ggtitle("k-means 3 groups")
p3.DAPC2.map

#Plotting DAPC axis 2 vs longitude
ggplot(data=tmp, aes(x=Lon, y=DAPC2, fill=G3)) + geom_point(shape=21, stroke=0.1, cex=2) + scale_fill_manual(values=c3[c(2,1,3)])
plot(tmp$DAPC2, tmp$Lon, pch=20)

#There is no pattern showing that fish closer to the Gulf break are closer to fish from the other group.
}

#Scatter plots
{```{R}```
par(mfrow=c(1,1))
scatter(xval.2.net$DAPC, cstar=0, col=c2,posi.da="bottomright")
scatter(xval.3.net$DAPC, cstar=0, col=c3,posi.da="bottomleft", add=T)
scatter(xval.4.net$DAPC, cstar=0, col=c4,posi.da="bottomright")
scatter(xval.5.net$DAPC, cstar=0, col=c5,posi.da="bottomright")
scatter(xval.6.net$DAPC, cstar=0, col=c6,posi.da="bottomright")

tmp.df <- data.frame(cbind(xval.3.net$DAPC$ind.coord,as.factor(xval.3.net$DAPC$grp)))
tmp.df$V3 <- as.factor(tmp.df$V3)
p3 <- ggplot(tmp.df, aes(x = LD1, y = LD2, color = V3, fill = V3)) + geom_point(size = 2, shape = 20) + 
	theme_bw() + scale_color_manual(values=c3) + stat_ellipse() + theme(legend.position='none') + ggtitle("DAPC with Kmeans=3")
p3

multiplot(p3,p3.1.map, p3.2.map, p3.3.map, cols=2)
ggsave("Angel_Shark_kmeans_clustaring_maps3_neutral.tif",multiplot(p3,p3.1.map, p3.2.map, p3.3.map, cols=2), device="tiff")


tmp.df <- data.frame(cbind(xval.4.net$DAPC$ind.coord,as.factor(xval.4.net$DAPC$grp)))
tmp.df$V4 <- as.factor(tmp.df$V4)
p4 <- ggplot(tmp.df, aes(x = LD1, y = LD2, color = V4, fill = V4)) + geom_point(size = 2, shape = 20) + 
	theme_bw() + scale_color_manual(values=c4) + stat_ellipse() + theme(legend.position='none') + ggtitle("DAPC with Kmeans=4")
p4

p4.23.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat, fill = G4, alpha =0.5), data=subset(tmp, G4==2 | G4==3), shape=21, color="black", stroke=0.1, size =2.5) + scale_fill_manual(values=c4[2:3]) + theme(legend.position="none") + ggtitle("Kmeans=4: Atlantic and West Gulf group")

multiplot(p4,p4.1.map, p4.23.map, p4.4.map, cols=2)
ggsave("Angel_Shark_kmeans_clustaring_maps4_neutral.tif",multiplot(p4,p4.1.map, p4.23.map, p4.4.map, cols=2), device="tiff")
}

#Composition plots
{```{R}```
gen.net@strata$G3 <- as.character(gen.net@strata$G3)
gen.net@strata$G3[gen.net@strata$G3==1] <- "East_GOM"
gen.net@strata$G3[gen.net@strata$G3==2] <- "Atlantic"
gen.net@strata$G3[gen.net@strata$G3==3] <- "West_GOM" 

setPop(gen.net)<-~G3
p2.comp<-ggcompoplot(xval.2.net$DAPC, gen.net, pal = c2, cols=3) + theme(axis.text.x = element_blank()) + ggtitle("K-means 2 Groups")
p3.comp<-ggcompoplot(xval.3.net$DAPC, gen.net, pal = c3, cols=1) + theme(axis.text.x = element_blank()) + ggtitle("K-means 3 Groups")
p4.comp<-ggcompoplot(xval.4.net$DAPC, gen.net, pal = c4, cols=3) + theme(axis.text.x = element_blank()) + ggtitle("K-means 4 Groups")
p5.comp<-ggcompoplot(xval.5.net$DAPC, gen.net, pal = c5, cols=3) + theme(axis.text.x = element_blank()) + ggtitle("K-means 5 Groups")
p6.comp<-ggcompoplot(xval.6.net$DAPC, gen.net, pal = c6, cols=3) + theme(axis.text.x = element_blank()) + ggtitle("K-means 6 Groups")

p2.comp
p3.comp
p4.comp
p5.comp
p6.comp

multiplot(p2.comp, p3.comp, p4.comp, p5.comp, p6.comp)
ggsave("Angel_Shark_kmeans_clustaring_comp.tif",multiplot(p2.comp, p3.comp, p4.comp, p5.comp, p6.comp), device="tiff")
ggsave("Angel_Shark_kmeans_clustaring_3_comp.tif", p3.comp, device="tiff")
}

#DAPC: Looking for loci driving the differences
#Plotting each Population together
{```{R}```
contrib <- loadingplot(xval.3.net$DAPC$var.contr, axis=1, thres=.001, lab.jitter=1)
pc.loci <- unique(matrix(unlist(strsplit(contrib$var.names, "[.]")),ncol=2,byrow=T)[,1])

#Setting the plots grid
x.dim <- ceiling(sqrt(length(pc.loci)))
y.dim <- ceiling(length(pc.loci)/x.dim)
par(mfrow=c(y.dim,x.dim))

#Define the Population
setPop(gen.net) <- ~POP

#Get the levels
pop.lev <- levels(pop(gen.net))

#Getting the data and plotting each locus
for(i in pc.loci){
#Get locus data
tmp.dat <- cbind(gen.net@tab[,grep(i, colnames(gen.net@tab))],as.character(pop(gen.net)))
tmp.dat <- data.frame(tmp.dat[,order(colnames(tmp.dat))])

#Make certain data is numeric
for(j in 2:ncol(tmp.dat)){tmp.dat[,j] <- as.numeric(as.matrix(tmp.dat[,j]))}

#Making the data into percents
plot.dat <- data.frame(matrix(ncol=length(pop.lev), nrow=(ncol(tmp.dat)-1)))
colnames(plot.dat) <- pop.lev
for(j in pop.lev){
plot.dat[,j] <- apply(tmp.dat[tmp.dat[,1]==j,2:ncol(tmp.dat)], 2, function(x) sum(x, na.rm=T))/sum(tmp.dat[tmp.dat[,1]==j,2:ncol(tmp.dat)], na.rm=T)
}

#Plotting the locus
barplot(as.matrix(plot.dat), beside=T, col=rep(col.plot, each=(ncol(tmp.dat)-1)), main=i, ylab="Percent")
}

}

#Plotting each allele together
{```{R}```
#Get contributing loci
contrib <- loadingplot(xval.3.net$DAPC$var.contr, axis=1, thres=.001, lab.jitter=1)
pc.loci <- unique(matrix(unlist(strsplit(contrib$var.names, "[.]")),ncol=2,byrow=T)[,1])

#Setting the plots grid
x.dim <- ceiling(sqrt(length(pc.loci)))
y.dim <- ceiling(length(pc.loci)/x.dim)
par(mfrow=c(y.dim,x.dim))

#Define the Population
setPop(gen.net) <- ~POP

#Get the levels
pop.lev <- levels(pop(gen.net))

#Getting the data and plotting each locus
for(i in pc.loci){
#Get locus data
tmp.dat <- cbind(gen.net@tab[,grep(i, colnames(gen.net@tab))],as.character(pop(gen.net)))
tmp.dat <- data.frame(tmp.dat[,order(colnames(tmp.dat))])

#Make certain data is numeric
for(j in 2:ncol(tmp.dat)){tmp.dat[,j] <- as.numeric(as.matrix(tmp.dat[,j]))}

#Making the data into percents
plot.dat <- data.frame(matrix(ncol=length(pop.lev), nrow=(ncol(tmp.dat)-1)))
colnames(plot.dat) <- pop.lev
for(j in pop.lev){
plot.dat[,j] <- apply(tmp.dat[tmp.dat[,1]==j,2:ncol(tmp.dat)], 2, function(x) sum(x, na.rm=T))/sum(tmp.dat[tmp.dat[,1]==j,2:ncol(tmp.dat)], na.rm=T)
}

#Adding haplotype names
h.name <- "H1"
for(j in 2:(ncol(tmp.dat)-1)){h.name <- c(h.name, paste("H",j,sep=""))}

#Plotting the locus
if(tail(pc.loci,1)==i){barplot(as.matrix(t(plot.dat)), beside=T, col=col.plot, main=i, legend.text=names(plot.dat), names.arg=h.name, ylab="Percent")
} else {barplot(as.matrix(t(plot.dat)), beside=T, col=col.plot, main=i, names.arg=h.name, ylab="Percent")
}
}

}}}}}}}}}}}}}}}} #Cleanup

#Looking for effect of removing alleles
{```{R}```
Inputs:
0) Genind object
1) DAPC object
2) Starting threshold
3) Incriments to change
4) Grouping (e.g. POP)
5) Axis

quantile(contrib$var.values, prob=0.99)

contrib$var.values[order(contrib$var.values, decreasing = T)]

GEN <- gen.net
DAPC <- xval.3.net$DAPC
THRES <- 0.852
#CHANGE <- 0.005
GROUP <- "POP"
AXIS <- 1
ALPHA <- 0.05

contrib <- rownames(xval.3.net$DAPC$var.contr)[which(xval.3.net$DAPC$var.contr[,AXIS] > quantile(xval.3.net$DAPC$var.contr[,AXIS], prob=THRES))]
pc.loci <- unique(matrix(unlist(strsplit(contrib, "[.]")),ncol=2,byrow=T)[,1])

set.loc<-locNames(gen.net)[which(!(locNames(gen.net) %in% pc.loci))]
tmp.keep<-gen.net[, loc=set.loc]
set.loc<-locNames(gen.net)[which((locNames(gen.net) %in% pc.loci))]
tmp.rm<-gen.net[, loc=set.loc]

# Attribute Variance
tmp.keep.result <- poppr.amova(tmp.keep, ~POP, quiet=T)
tmp.rm.result <- poppr.amova(tmp.rm, ~POP, quiet=T)
# Test for significance
tmp.keep.test <- randtest(tmp.keep.result, nrepet=5000)
tmp.rm.test <- randtest(tmp.rm.result, nrepet=5000)

cbind(tmp.keep.test$names, tmp.keep.test$pvalue)
cbind(tmp.rm.test$names, tmp.rm.test$pvalue)

X <- scaleGen(gen.net, NA.method="mean", scale=F)
pca1 <- dudi.pca(X,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

X.keep <- scaleGen(tmp.keep, NA.method="mean", scale=F)
pca.keep <- dudi.pca(X.keep,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

X.rm <- scaleGen(tmp.rm, NA.method="mean", scale=F)
pca.rm <- dudi.pca(X.rm,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

tiff("PC1_Loci.tif", res=300, height=6000, width=2000)
setPop(gen.net) <- setPop(tmp.keep) <- setPop(tmp.rm) <- ~POP
par(mfrow=c(3,1))
ade4::s.class(pca1$li, pop(gen.net), col=col.All, cstar=0, axesell=F)
mtext(paste("All data (n=",length(locNames(gen.net))," loci)", sep=""), 3, 2, adj = 0.95)
ade4::s.class(pca.keep$li, pop(tmp.keep), col=col.All, cstar=0, axesell=F)
mtext(paste("No Sig diff (n=",length(locNames(tmp.keep))," loci)", sep=""), 3, 2, adj = 0.95)
ade4::s.class(pca.rm$li, pop(tmp.rm), col=col.All, cstar=0, axesell=F)
mtext(paste("Sig POP (n=",length(locNames(tmp.rm))," loci)", sep=""), 3, 2, adj = 0.95)
dev.off()

`# Function to split out loci which are driving the difference between two PCA groups #`
# Need to start with a threshold between 0.51 and 0.99
Locus_hunt <- function(GEN, DAPC, THRES=0.8, GROUP="~POP", AXIS=1, ALPHA=0.05, MIN=0.5){
#Objects to put into the function

#GEN <- The genind object used to make a DAPC
#DAPC <- The DAPC oject made from the genind object
#THRES <- The precent of loci to remove during the 1st round
#GROUP <- The strata group that should be used
#AXIS <- The axis you would like to search along
#ALPHA <- The significance value you would like to work with 
#MIN <- The lower limit that the threshold can approach, but never reach

#Fills in missing values
if(missing(THRES)){THRES=0.8}
if(missing(GROUP)){GROUP="~POP"}
if(missing(AXIS)){AXIS=1}
if(missing(ALPHA)){ALPHA=0.5}
if(missing(MIN)){MIN=0.5}

# Sets up the varibles tested
GOOD <- as.vector(MIN)
BAD <- as.vector(1)
if(THRES<=MIN){THRES <- MIN + 0.05}
if(THRES>=0.9975){THRES <- 0.95}

# Loop to look for optimal value
while(abs(THRES-max(GOOD))>0.001){
if(length(GOOD)>20){cat(paste("Threshold not found\nPlease try a new starting point\nBest Threshold tried was",max(GOOD),"\n")); break}
print(paste("Processing threshold", THRES))
# Getting the loci to test
contrib <- rownames(DAPC$var.contr)[which(DAPC$var.contr[,AXIS] > quantile(DAPC$var.contr[,AXIS], prob=THRES))]
pc.loci <- unique(matrix(unlist(strsplit(contrib, "[.]")),ncol=2,byrow=T)[,1])

# Select out the data sets
set.loc<-locNames(GEN)[which(!(locNames(GEN) %in% pc.loci))]
tmp.keep<-GEN[, loc=set.loc]
set.loc<-locNames(GEN)[which((locNames(GEN) %in% pc.loci))]
tmp.rm<-GEN[, loc=set.loc]

# Attribute Variance
tmp.keep.result <- poppr.amova(tmp.keep, as.formula(GROUP), quiet=T)
tmp.rm.result <- poppr.amova(tmp.rm, as.formula(GROUP), quiet=T)

# Test for significance
tmp.keep.test <- randtest(tmp.keep.result)
tmp.rm.test <- randtest(tmp.rm.result)

#Tables for comparison
tmp.ktable <- data.frame(cbind(tmp.keep.test$names, tmp.keep.test$pvalue),row.names=1)
names(tmp.ktable) <- "Kept"
tmp.rtable <- data.frame(cbind(tmp.rm.test$names, tmp.rm.test$pvalue),row.names=1)
names(tmp.rtable) <- "Removed"
print(cbind(tmp.ktable, tmp.rtable))

#Decision of what to do next
if(as.numeric(as.matrix(tmp.ktable[nrow(tmp.ktable),1])) < ALPHA |	as.numeric(as.matrix(tmp.rtable[nrow(tmp.rtable),1])) > ALPHA){
	BAD <- c(BAD, THRES)
} else if(as.numeric(as.matrix(tmp.ktable[nrow(tmp.ktable),1])) > ALPHA | as.numeric(as.matrix(tmp.rtable[nrow(tmp.rtable),1])) < ALPHA){
	GOOD <- c(GOOD, THRES)
	STORE.GOOD.gen.keep <- tmp.keep
	STORE.GOOD.gen.rm <- tmp.rm
	STORE.GOOD.tab.keep <- tmp.ktable
	STORE.GOOD.tab.rm <- tmp.rtable
}
THRES <- mean(c(max(GOOD),min(BAD)))

}
THRES <- max(GOOD)

#Outputs
OUTPUT.list <- list()
OUTPUT.list[[1]] <- STORE.GOOD.gen.keep
OUTPUT.list[[2]] <- STORE.GOOD.gen.rm
OUTPUT.list[[3]] <- paste("The Best Threshold tested was ", max(GOOD), "\nThis removed ", length(locNames(STORE.GOOD.gen.rm)), " loci (", round(length(locNames(STORE.GOOD.gen.rm))/length(locNames(GEN)),3)*100,"%)\n",
"Kept p-value is ", STORE.GOOD.tab.keep[nrow(STORE.GOOD.tab.keep),1], "\nRemoved p-value is ", STORE.GOOD.tab.rm[nrow(STORE.GOOD.tab.rm),1], "\nData has been output to the 1st two objects of this list\n Item 1 contains the kept genind object\n Item 2 contains the removed genind object\n", sep="")
return(OUTPUT.list)
}

}}}}}}}}}}}}}}}}}}}#Cleanup

# Test variables
{```{R}```
GEN <- gen.net
DAPC <- xval.3.net$DAPC
THRES <- 0.5
GROUP <- "~POP"
AXIS <- 1
ALPHA <- 0.05
OUTPUT <- "TEST"

#Testing the function
Test.out <- Locus_hunt(gen.net, xval.3.net$DAPC, 0.8, "~POP", 1, 0.05)	#WORKED
cat(Test.out[[3]])

Test.out <- Locus_hunt(gen.net, xval.3.net$DAPC, 0.5, "~POP", 2, 0.05, MIN=0.25)	#WORKED
cat(Test.out[[3]])

Test.out <- Locus_hunt(gen.net, xval.3.net$DAPC, 0.4, "~POP", 2, 0.05, MIN=0)	#Crashed out; Last values ~0.0625
cat(Test.out[[3]])

Test.out <- Locus_hunt(gen.net, xval.3.net$DAPC, 0.5, "~POP", 1, 0.05)	#WORKED
cat(Test.out[[3]])

Test.out <- Locus_hunt(gen.net, xval.3.net$DAPC, 1, "~POP", 1, 0.05)	#
cat(Test.out[[3]])


#Plotting the output
X <- scaleGen(gen.net, NA.method="mean", scale=F)
pca1 <- dudi.pca(X,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

X.keep <- scaleGen(Test.out[[1]], NA.method="mean", scale=F)
pca.keep <- dudi.pca(X.keep,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

X.rm <- scaleGen(Test.out[[2]], NA.method="mean", scale=F)
pca.rm <- dudi.pca(X.rm,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

#tiff("PC1_Loci.tif", res=300, height=6000, width=2000)
setPop(gen.net) <- setPop(Test.out[[1]]) <- setPop(Test.out[[2]]) <- ~POP
par(mfrow=c(3,1))
ade4::s.class(pca1$li, pop(gen.net), col=col.All, cstar=0, axesell=F)
mtext(paste("All data (n=",length(locNames(gen.net))," loci)", sep=""), 3, 2, adj = 0.95)
ade4::s.class(pca.keep$li, pop(Test.out[[1]]), col=col.All, cstar=0, axesell=F)
mtext(paste("No Sig diff (n=",length(locNames(Test.out[[1]]))," loci)", sep=""), 3, 2, adj = 0.95)
ade4::s.class(pca.rm$li, pop(Test.out[[2]]), col=col.All, cstar=0, axesell=F)
mtext(paste("Sig POP (n=",length(locNames(Test.out[[2]]))," loci)", sep=""), 3, 2, adj = 0.95)
#dev.off()

}


#### sPCA ####
#jitter data
#Testing if it works in a small case
{```{R}```
setPop(gen.net)<- ~G3
loc2 <- data.frame(matrix(nrow=length(indNames(gen.net))))
for(i in c("Lon","Lat")){loc2[,i] <- as.numeric(as.matrix(gen.net@strata[,i]))}
loc2[,1] <- indNames(gen.net)
names(loc2)[1] <- "INDV"

gen.net@other$lat<-gen.net@strata[,c("Lon","Lat")]
gen.net@other$lat[,1]<-as.numeric(as.character(gen.net@strata$Lon))
gen.net@other$lat[,2]<-as.numeric(as.character(gen.net@strata$Lat))	#As numeric

#jitter data
while(!(exists("cn"))){
gen.net@other$lat[,1]<-jitter(gen.net@other$lat[,1])
gen.net@other$lat[,2]<-jitter(gen.net@other$lat[,2])
try(cn<-chooseCN(gen.net$other$lat, type=1))
}
}

#Making networks
{```{R}```
for(i in 1:6){
  assign(paste("cn.type",i, sep=""), chooseCN(gen.net$other$lat, type=i))
}

#Check networks for issues
cn.type1
cn.type2
cn.type3
cn.type4
cn.type5
cn.type6
}

#Plotting networks
{```{R}```
tiff("cn.with.tif",res=200, width=3000, height=2000)
par(mfrow=c(2,3))
plot(cn.type1, coords=gen.net$other$lat)
title("Type 1 with tunnels")
plot(cn.type2, coords=gen.net$other$lat)
title("Type 2 with tunnels")
plot(cn.type3, coords=gen.net$other$lat)
title("Type 3 with tunnels")
plot(cn.type4, coords=gen.net$other$lat)
title("Type 4 with tunnels")
plot(cn.type5, coords=gen.net$other$lat)
title("Type 5 with tunnels")
plot(cn.type6, coords=gen.net$other$lat)
title("Type 6 with tunnels")
dev.off()
}

#Running sPCA
{```{R}```
setPop(gen.net)<- ~G3
spca<-data.frame(row.names=indNames(gen.net))
for (i in 1:6){
  remove(spca1)
  assign(paste("spca_type", i,sep=""), spca(gen.net, xy=gen.net$other$lat, type=i, scannf=FALSE, nfposi=3, nfnega=0))
  print(paste("cn type", i,"complete", sep = " "))
}

#Plotting spcas
#Test
par(mfrow=c(2,3))
for (i in 1:6){
s.class(get(paste("spca_type", i,sep="")),pop(gen.net), col=c3 ,cstar=0, cellipse=1, grid =FALSE)
}
}

#Producing multiple iterations of jittered lat/longs which work with chooseCN types 1-4
{```{R}```
jitter<-data.frame(row.names=indNames(gen.net))
for (i in 1:100){
  a<-0
  gen.net@other$lat<-loc2[,c(2,3)]
  if(try(length(cn),silent=TRUE)>0){remove(cn)}
  while (a==0){
    gen.net$other$lat[,1]<-jitter(gen.net$other$lat[,1])
    gen.net$other$lat[,2]<-jitter(gen.net$other$lat[,2])
    try(cn<-chooseCN(gen.net$other$lat, type=1),silent=TRUE)
    try(a<-length(cn),silent=TRUE)
  }
  jitter[,(i*2-1)]<-gen.net$other$lat[,1]
  jitter[,(i*2)]<-gen.net$other$lat[,2]
  print(paste("iteration", i,"complete", sep = " "))
}

remove(a)

#Testing if jittered lat/long worked
for (i in 1:100){
  cn<-chooseCN(jitter[,(i*2-1):(i*2)], type=1)
  print(i)
}

remove(cn)

#Producing multiple iterations of spca data from jittered lat/longs
setPop(gen.net)<- ~G3
spca<-data.frame(row.names=indNames(gen.net))
for (i in 1:100){
  remove(spca1)
  spca1<-spca(gen.net, xy=jitter[,(i*2-1):(i*2)], type=1, scannf=FALSE, nfposi=3, nfnega=0)
  spca[,(i*2-1)]<-spca1$li[,1]
  spca[,(i*2)]<-spca1$li[,2]
  print(paste("iteration", i,"complete", sep = " "))
}

remove(spca1)

#Plotting spcas
#Test
dev.off()
s.class(spca[,(1*2-1):(1*2)],pop(gen.net), col=funky(length(levels(pop(gen.net)))),cstar=0, cellipse=1, grid =FALSE)

s.class(spca[,(1*2-1):(1*2)],pop(gen.net), col=funky(length(levels(pop(gen.net)))),cstar=1, cellipse=1, grid =FALSE)

#Plot all 100 spcas to file
tiff(filename = "gen.vcf.type1.tif", width = 11000, height = 11000, res = 200)
par(mfrow=c(10,10))
for (i in 1:100){
  s.class(spca[,(i*2-1):(i*2)],pop(gen.net), col=funky(length(levels(pop(gen.net)))),cstar=0, cellipse=1, grid =FALSE)
}
dev.off()

#Average each population (get the centroid)
test<-data.frame(row.names=levels(pop(gen.net)))
for(i in 1:200){
  test[,i]<-tapply(spca[,i],pop(gen.net), mean)
}

dim(test)
test[1:13,1:5]
test1.1<-as.matrix(test)
}

#Needs alterations
{```{R}```
#Look for the difference between a few populations in the x and y directions
test2<-data.frame(row.names=c("JC-VC","JC-DT","JC-MG", "JC-FL", "VC-DT", "VC-MG", "VC-FL", "DT-MG", "DT-FL", "MG-FL"))
for (i in 1:200){
a<-test1.1[5,i]-test1.1[12,i]
b<-test[5,i]-test[3,i]
d<-test[5,i]-test[7,i]
e<-test[5,i]-test[4,i]
f<-test[12,i]-test[3,i]
g<-test[12,i]-test[7,i]
h<-test[12,i]-test[4,i]
j<-test[3,i]-test[7,i]
k<-test[3,i]-test[4,i]
l<-test[7,i]-test[4,i]
vector<-as.matrix(c(a,b,d,e,f,g,h,j,k,l))
test2[,i]<-vector[,1]
}

remove(a,b,d,e,f,g,h,i,j,k,l)

test2[1:10,1:5]

#Find the distance between two population centroids
test3<-data.frame(row.names=c("JC-VC","JC-DT","JC-MG", "JC-FL", "VC-DT", "VC-MG", "VC-FL", "DT-MG", "DT-FL", "MG-FL"))
for (i in 1:100){
test3[,i]<-sqrt(test2[,(i*2-1)]^2 + test2[,(i*2)]^2)
}

test3[1:10,1:5]

#Find basic stats of the differences
test4<-data.frame(row.names=c("JC-VC","JC-DT","JC-MG", "JC-FL", "VC-DT", "VC-MG", "VC-FL", "DT-MG", "DT-FL", "MG-FL"))
for (i in 1:10){
  test4[i,1]<-max(test3[i,])
  test4[i,2]<-min(test3[i,])
  test4[i,3]<-max(test3[i,])-min(test3[i,])
  test4[i,4]<-sd(test3[i,])
  test4[i,5]<-mean(as.matrix(test3[i,]))
  }

colnames(test4)<-c("Max","Min","Range","StDev", "Mean")

test4

#Finding "most average" jitter
test5<-test3-test4[,5]
test6<-colSums(abs(test5))
which(test6==min(test6))

#Find the jitters with the most extreme differences
#Max side ot the graph
xtreme<-vector(length=20)
for (i in 1:10){
  xtreme[i]<-which(test3[i,]==test4[i,1])
}

#Min side ot the graph
for (i in 1:10){
  xtreme[(i+10)]<-which(test3[i,]==test4[i,2])
}

xtreme.o<-xtreme[order(xtreme[,(n+w+2)]),]
xtreme.u<-unique(xtreme.o)

#Plot those spcas with the most and least differences
dev.off()
tiff("plot.tif", res=200, width=4000, height=4000)
par(mfrow=c(4,4))
for(i in xtreme.u){
  s.class(spca[,(i*2-1):(i*2)],pop(gen.net), col=funky(length(levels(pop(gen.net)))),cstar=0, cellipse=1, grid =FALSE)
}
dev.off()

#Plot the spca with the the smallest amount of differences overall
setPop(gen.net)<- ~POP2
tiff("Avg_spca.type1.tif", res=300, width=2500, height=2500)
s.class(spca[,(which(test6==min(test6))*2-1):(which(test6==min(test6))*2)],pop(gen.net), col=funky(length(levels(pop(gen.net)))),cstar=0, cellipse=1, grid =FALSE)
legend(x=-5, y=4.5,legend=levels(pop(gen.net)),col=funky(length(levels(pop(gen.net)))), cex=0.7, pch=16)
dev.off()

#Plot the distributions of the x and y differences between locations
tiff("dists.tif", res=300, width=7500, height=3000)
par(mfrow=c(2,5))
for(i in 1:10){
  hist(as.numeric(test2[i,]), breaks = 20, main = title[i])
}
dev.off()


#Plot the distributions of the differences between locations
title<-c("JC-VC","JC-DT","JC-MG", "JC-FL", "VC-DT", "VC-MG", "VC-FL", "DT-MG", "DT-FL", "MG-FL")
tiff("dists.tif", res=300, width=7500, height=3000)
par(mfrow=c(2,5))
for(i in 1:10){
  hist(as.numeric(test3[i,]), breaks = 20, main = title[i])
}
dev.off()
}

##Looking at different canned networks
#Using "most average" network (#27 in jitter)
#Exporting different connection networks
#Used d1=0, d2=4.65, k=55
{```{R}```
for(i in 1:6){
  dumby<-chooseCN(xy=jitter[,(27*2-1):(27*2)], type=i)
  temp<-neig2mat(nb2neig(dumby))
  colnames(temp)<-indNames(gen.net)
  rownames(temp)<-indNames(gen.net)
  write.csv(temp, file= paste("cn.type",i,".csv", sep=""))
}

#Trial reading single network back into R
temp<-read.csv(paste("cn.type",3,".edit.csv",sep=""), header=TRUE)
temp10<-data.matrix(temp)
assign(paste("cn",3,".e",sep=""),mat2listw(temp10[1:374,2:375])$neighbours)

#Reimporting exported networks and editted networks
#Type 2,3,4 networks had no connection between DT and ML
#In 2-4, ML58 was connected to FL18; In Type 2 ML66 was connected to FL14
#In 2-4, DT17 was connected to ML66 because this was the shortest distance between these groups
#In Type 2 DT15 was connected to ML77 because this was the 2nd shortest distance excluding DT17 and ML66
#Did not readjust the number of connections to the DT and FL points.

for(i in 1:6){
temp<-read.csv(paste("cn.type",i,".edit.csv",sep=""), header=TRUE)
temp10<-data.matrix(temp)
assign(paste("cn",i,".e",sep=""),mat2listw(temp10[1:374,2:375])$neighbours)
temp<-read.csv(paste("cn.type",i,".csv",sep=""), header=TRUE)
temp10<-data.matrix(temp)
assign(paste("cn",i,sep=""),mat2listw(temp10[1:374,2:375])$neighbours)
}

#Check networks for issues
cn1
cn2
cn3
cn4
cn5
cn6

#Plotting original networks
tiff("cn.with.tif",res=200, width=3000, height=2000)
par(mfrow=c(2,3))
plot(cn1, coords=loc2)
title("Type 1 with tunnels")
plot(cn2, coords=loc2)
title("Type 2 with tunnels")
plot(cn3, coords=loc2)
title("Type 3 with tunnels")
plot(cn4, coords=loc2)
title("Type 4 with tunnels")
plot(cn5, coords=loc2)
title("Type 5 with tunnels")
plot(cn6, coords=loc2)
title("Type 6 with tunnels")
dev.off()

#Plotting editted networks
tiff("cn.without.tif",res=200, width=3000, height=2000)
par(mfrow=c(2,3))
plot(cn1.e, coords=loc2)
title("Type 1 without tunnels")
plot(cn2.e, coords=loc2)
title("Type 2 without tunnels")
plot(cn3.e, coords=loc2)
title("Type 3 without tunnels")
plot(cn4.e, coords=loc2)
title("Type 4 without tunnels")
plot(cn5.e, coords=loc2)
title("Type 5 without tunnels")
plot(cn6.e, coords=loc2)
title("Type 6 without tunnels")
dev.off()

#Running SPCAs of all the original networks
net.test.w<-data.frame(row.names=indNames(gen.net))
for (i in 1:6){
  remove(spca1)
  spca1<-spca(gen.net, xy=jitter[,(27*2-1):(27*2)], cn=get(paste("cn",i, sep="")), scannf=FALSE, nfposi=3, nfnega=0)
  net.test.w[,(i*2-1)]<-spca1$li[,1]
  net.test.w[,(i*2)]<-spca1$li[,2]
  print(paste("iteration", i,"complete", sep = " "))
}

#Running SPCAs of all the editted networks
net.test.wo<-data.frame(row.names=indNames(gen.net))
for (i in 1:6){
  remove(spca1)
  spca1<-spca(gen.net, xy=jitter[,(27*2-1):(27*2)], cn=get(paste("cn",i,".e", sep="")), scannf=FALSE, nfposi=3, nfnega=0)
  net.test.wo[,(i*2-1)]<-spca1$li[,1]
  net.test.wo[,(i*2)]<-spca1$li[,2]
  print(paste("iteration", i,"complete", sep = " "))
}

#Plotting original networks in PCA format
tiff("SPCA_PCA with tunnels.tif")
par(mfrow=c(2,3))
for (i in 1:6){
  s.class(net.test.w[,(i*2-1):(i*2)],pop(gen.net), col=funky(length(levels(pop(gen.net)))),cstar=0, cellipse=1, grid =FALSE)
  title("Type")
}
dev.off()

#Plotting editted networks in PCA format
tiff("SPCA_PCA without tunnels.tif")
par(mfrow=c(2,3))
for (i in 1:6){
  s.class(net.test.wo[,(i*2-1):(i*2)],pop(gen.net), col=funky(length(levels(pop(gen.net)))),cstar=0, cellipse=1, grid =FALSE)
  title("Type")
}
dev.off()
}

}}}}}}}}}}}}}}}}}}}} # Clean-up


## RDA based upon the reference http://cc.oulu.fi/~jarioksa/opetus/metodi/sessio2.pdf and Section 6.10 in Numeriacl Ecolgy for R ###
## and Section 7.3.2 in Numerical Ecolgy for R
#Neutral Loci#
{```{R}```
#All loci, pre neutral filtering
loc.net<-gen.net@other$lat
loc.poly <- poly(as.matrix(loc.net), degree = 3, raw = TRUE)
loc.poly <- data.frame(cbind(loc.poly, gen.net@strata$Depth))
colnames(loc.poly) <-c("Lon", "Lon2", "Lon3", "Lat", "Lon_Lat", "Lon2_Lat", "Lat2", "Lon_Lat2", "Lat3", "Depth")

for(i in c(18,seq(25,113))){
tmp<-data.frame(strata[match(loc.poly[,1],strata$Lon),i])
loc.poly <- cbind(loc.poly, tmp)}
colnames(loc.poly) <-c("Lon", "Lon2", "Lon3", "Lat", "Lon_Lat", "Lon2_Lat", "Lat2", "Lon_Lat2", "Lat3", "Depth", colnames(strata)[25:113])

loc.poly <- loc.poly[,colSums(is.na(loc.poly))==0]

X <- scaleGen(gen.net, NA.method="mean", scale=F, center=T)
m1<-rda(X ~ .,loc.poly)
m0<-rda(X ~ 1,loc.poly)

#Fwd building
m<-step(m0, scope=formula(m1), test="perm")
m
{#Results
Start:  AIC=440.97
X ~ 1

           Df    AIC      F Pr(>F)
<none>        440.97
+ Lat3      1 441.01 1.9273  0.005 **
+ Lat2      1 441.01 1.9263  0.005 **
+ Lat       1 441.01 1.9224  0.005 **
+ Lon_Lat2  1 441.04 1.9006  0.005 **
+ Lon       1 441.08 1.8520  0.005 **
+ Lon2      1 441.11 1.8299  0.005 **
+ Lon3      1 441.13 1.8061  0.005 **
+ Depth     1 441.23 1.7043  0.005 **
+ Lon2_Lat  1 441.29 1.6434  0.005 **
+ Lon_Lat   1 441.30 1.6344  0.005 **
+ OXY_MG    1 441.38 1.5562  0.005 **
+ TL        2 442.71 1.0959  0.005 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> m
Call: rda(formula = X ~ 1, data = loc.poly)

              Inertia Rank
Total            1208
Unconstrained    1208   61
Inertia is variance

Eigenvalues for unconstrained axes:
  PC1   PC2   PC3   PC4   PC5   PC6   PC7   PC8
38.66 24.12 22.70 22.55 22.41 22.26 22.11 21.98
(Showing 8 of 61 unconstrained eigenvalues)
}

#Reverse stepwise
mback <- step(m1, test="perm")
mback
{#Results
Call: rda(formula = X ~ 1, data = loc.poly)

              Inertia Rank
Total            1208
Unconstrained    1208   61
Inertia is variance

Eigenvalues for unconstrained axes:
  PC1   PC2   PC3   PC4   PC5   PC6   PC7   PC8
38.66 24.12 22.70 22.55 22.41 22.26 22.11 21.98
(Showing 8 of 61 unconstrained eigenvalues)
}

#Permutation Fwd building
m <- ordistep(m0, scope = formula(m1))
m
{#Results
Start: X ~ 1

           Df    AIC      F Pr(>F)
+ Lat3      1 441.01 1.9273  0.005 **
+ Lat2      1 441.01 1.9263  0.005 **
+ Lat       1 441.01 1.9224  0.005 **
+ Lon_Lat2  1 441.04 1.9006  0.005 **
+ Lon       1 441.08 1.8520  0.005 **
+ Lon2      1 441.11 1.8299  0.005 **
+ Lon3      1 441.13 1.8061  0.005 **
+ Depth     1 441.23 1.7043  0.005 **
+ Lon2_Lat  1 441.29 1.6434  0.005 **
+ Lon_Lat   1 441.30 1.6344  0.005 **
+ OXY_MG    1 441.38 1.5562  0.005 **
+ TL        2 442.71 1.0959  0.005 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Step: X ~ Lat3

       Df    AIC      F Pr(>F)
- Lat3  1 440.97 1.9273  0.005 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

           Df    AIC      F Pr(>F)
+ Lon3      1 441.80 1.1610  0.005 **
+ Lon2      1 441.80 1.1573  0.005 **
+ Lon       1 441.81 1.1523  0.005 **
+ Lat       1 441.82 1.1405  0.005 **
+ Lat2      1 441.82 1.1379  0.005 **
+ Lon2_Lat  1 441.83 1.1368  0.005 **
+ Lon_Lat   1 441.86 1.1055  0.005 **
+ Lon_Lat2  1 441.91 1.0541  0.025 *
+ Depth     1 441.93 1.0405  0.060 .
+ OXY_MG    1 441.94 1.0297  0.115
+ TL        2 442.86 1.0229  0.145
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Step: X ~ Lat3 + Lon3

       Df    AIC      F Pr(>F)
- Lon3  1 441.01 1.1610  0.005 **
- Lat3  1 441.13 1.2789  0.005 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

           Df    AIC      F Pr(>F)
+ Lon       1 442.69 1.0530  0.030 *
+ Lon2      1 442.69 1.0517  0.030 *
+ Lon_Lat   1 442.71 1.0295  0.175
+ Lon_Lat2  1 442.71 1.0307  0.185
+ Lon2_Lat  1 442.71 1.0293  0.205
+ TL        2 443.64 1.0100  0.310
+ Lat       1 442.72 1.0162  0.360
+ OXY_MG    1 442.73 1.0133  0.405
+ Lat2      1 442.72 1.0173  0.440
+ Depth     1 442.76 0.9863  0.715
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Step: X ~ Lat3 + Lon3 + Lon

       Df    AIC      F Pr(>F)
- Lat3  1 441.75 1.0089  0.275
- Lon   1 441.80 1.0530  0.035 *
- Lon3  1 441.81 1.0615  0.020 *
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Step: X ~ Lon3 + Lon

           Df    AIC      F Pr(>F)
+ Lon2      1 442.66 1.0336  0.160
+ TL        2 443.60 1.0092  0.415
+ Lon_Lat2  1 442.69 1.0073  0.445
+ Lat3      1 442.69 1.0089  0.465
+ Lon_Lat   1 442.69 1.0064  0.495
+ Lat2      1 442.69 1.0085  0.505
+ Lat       1 442.69 1.0079  0.505
+ Lon2_Lat  1 442.69 1.0045  0.555
+ OXY_MG    1 442.69 1.0072  0.580
+ Depth     1 442.71 0.9876  0.630

       Df    AIC      F Pr(>F)
- Lon3  1 441.08 1.2793  0.005 **
- Lon   1 441.13 1.3240  0.005 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

           Df    AIC      F Pr(>F)
+ Lon2      1 442.66 1.0336  0.180
+ OXY_MG    1 442.69 1.0072  0.380
+ TL        2 443.60 1.0092  0.410
+ Lon2_Lat  1 442.69 1.0045  0.450
+ Lon_Lat   1 442.69 1.0064  0.475
+ Lat2      1 442.69 1.0085  0.485
+ Lat3      1 442.69 1.0089  0.520
+ Lat       1 442.69 1.0079  0.525
+ Lon_Lat2  1 442.69 1.0073  0.530
+ Depth     1 442.71 0.9876  0.685

> m
Call: rda(formula = X ~ Lon3 + Lon, data = loc.poly)

                Inertia Proportion Rank
Total         1.208e+03  1.000e+00
Constrained   6.102e+01  5.053e-02    2
Unconstrained 1.147e+03  9.495e-01   59
Inertia is variance

Eigenvalues for constrained axes:
 RDA1  RDA2
38.31 22.71

Eigenvalues for unconstrained axes:
   PC1    PC2    PC3    PC4    PC5    PC6    PC7    PC8
22.785 22.574 22.411 22.348 22.142 22.028 21.866 21.752
(Showing 8 of 59 unconstrained eigenvalues)
}

m$anova
{#Results
       Df    AIC      F Pr(>F)
+ Lat3  1 441.01 1.9273  0.005 **
+ Lon3  1 441.80 1.1610  0.005 **
+ Lon   1 442.69 1.0530  0.030 *
- Lat3  1 441.75 1.0089  0.275
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
}

m_ord<-rda(X ~ Lat3 + Lat + Lon3 + Lon, loc.poly)

anova(m_ord, by="mar", permutations=10000)
{#Results
Permutation test for rda under reduced model
Marginal effects of terms
Permutation: free
Number of permutations: 10000

Model: rda(formula = X ~ Lat3 + Lat + Lon3 + Lon, data = loc.poly)
         Df Variance      F Pr(>F)
Lat3      1    19.82 1.0202 0.1817
Lat       1    19.80 1.0193 0.1930
Lon3      1    20.60 1.0603 0.0344 *
Lon       1    20.50 1.0554 0.0421 *
Residual 57  1107.20
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
}

anova(m_ord, by="axis", permutations=10000)
{#Results
Permutation test for rda under reduced model
Forward tests for axes
Permutation: free
Number of permutations: 10000

Model: rda(formula = X ~ Lat3 + Lat + Lon3 + Lon, data = loc.poly)
         Df Variance      F    Pr(>F)
RDA1      1    38.34 1.9740 9.999e-05 ***
RDA2      1    22.78 1.1726 9.999e-05 ***
RDA3      1    19.78 1.0183    0.7596
RDA4      1    19.52 1.0049    0.5271
Residual 57  1107.20
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
}

m_ord2<-rda(X ~ Lat3 + Lat, loc.poly)
anova(m_ord2, by="mar", permutations=10000)
{#Results
Permutation test for rda under reduced model
Marginal effects of terms
Permutation: free
Number of permutations: 10000

Model: rda(formula = X ~ Lat3 + Lat, data = loc.poly)
         Df Variance      F Pr(>F)
Lat3      1    22.28 1.1453 0.0015 **
Lat       1    22.19 1.1405 0.0017 **
Residual 59  1147.85
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
}

anova(m_ord2, by="axis", permutations=10000)
{#Results
Permutation test for rda under reduced model
Forward tests for axes
Permutation: free
Number of permutations: 10000

Model: rda(formula = X ~ Lat3 + Lat, data = loc.poly)
         Df Variance      F    Pr(>F)
RDA1      1    37.58 1.9319 9.999e-05 ***
RDA2      1    22.19 1.1405 9.999e-05 ***
Residual 59  1147.85
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
}

# Unadjusted R^2 retrieved from the rda object
{```{R}```
R2 <- RsquareAdj(m_ord2)$r.squared
R2
#0.04949641
}
# Adjusted R^2 retrieved from the rda object
{```{R}```
R2adj <- RsquareAdj(m_ord2)$adj.r.squared
R2adj
#0.01727595
}

#Partitioned variance
{```{R}```
mod <- varpart(X, ~ loc.poly$Lat3, ~ loc.poly$Lat)
plot(mod)
mod
{#Results
Partition of variance in RDA

Call: varpart(Y = X, X = ~loc.poly$Lat3, ~loc.poly$Lat)

Explanatory tables:
X1:  ~loc.poly$Lat3
X2:  ~loc.poly$Lat

No. of explanatory tables: 2
Total variation (SS): 73665
            Variance: 1207.6
No. of observations: 62

Partition table:
                     Df R.squared Adj.R.squared Testable
[a+b] = X1            1   0.03112       0.01497     TRUE
[b+c] = X2            1   0.03104       0.01490     TRUE
[a+b+c] = X1+X2       2   0.04950       0.01728     TRUE
Individual fractions
[a] = X1|X2           1                 0.00238     TRUE
[b]                   0                 0.01259    FALSE
[c] = X2|X1           1                 0.00230     TRUE
[d] = Residuals                         0.98272    FALSE
---
Use function ‘rda’ to test significance of fractions of interest
}
}

###Looking for "significant" loadings (https://popgen.nescent.org/2018-03-27_RDA_GEA.html)###
{```{R}```
load.rda <- scores(m_ord2, choices=c(1:2), display="species")

cand1 <- outliers(load.rda[,1],3)
cand2 <- outliers(load.rda[,2],3)
ncand <- length(cand1) + length(cand2)
ncand			
#328

cand1 <- cbind.data.frame(rep(1,times=length(cand1)), names(cand1), unname(cand1))
cand2 <- cbind.data.frame(rep(2,times=length(cand2)), names(cand2), unname(cand2))

colnames(cand1) <- colnames(cand2) <- c("axis","snp","loading")

cand <- rbind(cand1, cand2)
cand$snp <- as.character(cand$snp)

foo <- matrix(nrow=(ncand), ncol=2)  # 8 columns for 8 predictors
colnames(foo) <- colnames(loc.poly[,c("Lat3","Lat")])

X <- scaleGen(gen.net, NA.method="mean", scale=F)

for (i in 1:length(cand$snp)) {
  nam <- cand[i,2]
  snp.gen <- X[,nam]
  foo[i,] <- apply(loc.poly[,c(3,1)],2,function(x) cor(x,snp.gen))
}

cand <- cbind.data.frame(cand,foo)  
head(cand)

length(cand$snp[duplicated(cand$snp)])
foo <- cbind(cand$axis, duplicated(cand$snp)) 
table(foo[foo[,1]==1,2]) 
table(foo[foo[,1]==2,2]) 
cand <- cand[!duplicated(cand$snp),]

for (i in 1:length(cand$snp)) {
  bar <- cand[i,]
  cand[i,6] <- names(which.max(abs(bar[4:5]))) # gives the variable
  cand[i,7] <- max(abs(bar[4:5]))              # gives the correlation
}

colnames(cand)[6] <- "predictor"
colnames(cand)[7] <- "correlation"

table(cand$predictor) 

col.fill<-colnames(gen.net@tab)
empty.fill<-subset(col.fill, !col.fill %in% cand$snp)
for(i in cand$snp){col.fill[col.fill==i]<-cand[cand$snp==i,6]}
for(i in empty.fill){col.fill[col.fill==i]<-"#00FF0000"}
col.fill[col.fill=="Lat"] <- '#0064FF'
col.fill[col.fill=="Lat3"] <- '#00007D'
table(col.fill)

plot(m, type="n", scaling=3, xlim=c(-0.6,0.5), ylim=c(-0.5,0.7))
points(m, display="species", pch=21, cex=1, col="gray32", bg=col.fill, scaling=3, xlim=c(-0.6,0.5), ylim=c(-0.5,0.7))
text(m, scaling=3, display="bp", col="#0868ac", cex=1)
legend(x=0.3, y=-0.2, legend=c("Lat3 (n=149)","Lat (n=177)"),col=c('#00007D','#0064FF'),pch=21, pt.bg =c('#00007D','#0064FF'))

tiff("RDA_sig_inds.tif",res=200, width=1500, height=1500)
plot(m, type="n", scaling=3, xlim=c(-0.6,0.5), ylim=c(-0.5,0.7))
points(m, display="species", pch=21, cex=1, col="gray32", bg=col.fill, scaling=3, xlim=c(-0.6,0.5), ylim=c(-0.5,0.7))
text(m, scaling=3, display="bp", col="#0868ac", cex=1)
legend(x=0.3, y=-0.2, legend=c("Lat3 (n=149)","Lon_Lat (n=177)"),col=c('#00007D','#0064FF'),pch=21, pt.bg =c('#00007D','#0064FF'))
dev.off()

write.table(cand,file="RDA_Candidate_loci.txt",quote=F,row.names=F)

cand.out<-unique(matrix(unlist(strsplit(cand$snp, "[.]")),ncol=2,byrow=T)[,1]) 
#236 loci

#Plotting RDA "outlier" loci in a PCA framwoork
gen.net@strata$G3 <- as.character(gen.net@strata$G3)
gen.net@strata$G3[gen.net@strata$G3==1] <- "East_GOM"
gen.net@strata$G3[gen.net@strata$G3==2] <- "Atlantic"
gen.net@strata$G3[gen.net@strata$G3==3] <- "West_GOM" 

set.loc<-locNames(gen.net)[which(!(locNames(gen.net) %in% cand.out))]
gen.RDA.in<-gen.net[, loc=set.loc]
set.loc<-locNames(gen.net)[which(locNames(gen.net) %in% cand.out)]
gen.RDA.out<-gen.net[, loc=set.loc]

X.net <- scaleGen(gen.net, NA.method="mean", scale=F)
pca.net <- dudi.pca(X.net,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

X.RDA.in <- scaleGen(gen.RDA.in, NA.method="mean", scale=F)
pca.RDA.in <- dudi.pca(X.RDA.in,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

X.RDA.out <- scaleGen(gen.RDA.out, NA.method="mean", scale=F)
pca.RDA.out <- dudi.pca(X.RDA.out,cent=FALSE,scale=FALSE,scannf=FALSE,nf=5000)

setPop(gen.net) <- setPop(gen.RDA.out) <- setPop(gen.RDA.in) <- ~G3

tiff("PCA_of_RDA_outliers.tif", res=300, height=6000, width=2000)
par(mfrow=c(3,1))
ade4::s.class(pca.net$li, pop(gen.net), col=col.All, cstar=0, axesell=F)
mtext(paste("All data (n=",length(locNames(gen.net))," loci)", sep=""), 3, 2, adj = 0.95)
ade4::s.class(pca.RDA.in$li, pop(gen.RDA.in), col=col.All, cstar=0, axesell=F)
mtext(paste("RDA inlier (n=",length(locNames(gen.RDA.in))," loci)", sep=""), 3, 2, adj = 0.95)
ade4::s.class(pca.RDA.out$li, pop(gen.RDA.out), col=col.All, cstar=0, axesell=F)
mtext(paste("RDA outlier (n=",length(locNames(gen.RDA.out))," loci)", sep=""), 3, 2, adj = 0.95)
dev.off()

}}}}}}}}}}}}}}}}}}}#Clean-up

#RDA of spatial data
#Making Moran's I eiganvectors

dbMEM <- dbmem(gen.net@other$lat, MEM.autocor="positive")
dim(dbMEM)
#Only 1 MEM
ordisurf(gen.net@other$lat[,1:2], dbMEM[,1])

#Doing permutation selection
X.net <- scaleGen(gen.net, NA.method="mean", scale=F, center=T)
m1<-rda(X.net ~ ., dbMEM)
m0<-rda(X.net ~ 1, dbMEM)

m.ord <- ordistep(m0, scope = formula(m1), Pin=0.05, Pout=0.10, permutations = how(nperm = 999))
{ #Results
Start: X.net ~ 1

       Df    AIC     F Pr(>F)
+ MEM1  1 440.98 1.954  0.002 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Step: X.net ~ MEM1

       Df    AIC     F Pr(>F)
- MEM1  1 440.97 1.954  0.002 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
}

m.ord
{ #Results
Call: rda(formula = X.net ~ MEM1, data = dbMEM)

                Inertia Proportion Rank
Total         1.208e+03  1.000e+00
Constrained   3.809e+01  3.154e-02    1
Unconstrained 1.170e+03  9.685e-01   60
Inertia is variance

Eigenvalues for constrained axes:
 RDA1
38.09

Eigenvalues for unconstrained axes:
   PC1    PC2    PC3    PC4    PC5    PC6    PC7    PC8
24.266 22.703 22.577 22.409 22.261 22.109 21.997 21.784
(Showing 8 of 60 unconstrained eigenvalues)
}

anova(m.ord)
{ #Results
Permutation test for rda under reduced model
Permutation: free
Number of permutations: 999

Model: rda(formula = X.net ~ MEM1, data = dbMEM)
         Df Variance     F Pr(>F)
Model     1    38.09 1.954  0.001 ***
Residual 60  1169.53
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
}

#What does this look like just in the Gulf?
keep.ind <- gen.net@strata$INDV[gen.net@strata$POP!="Atl"]
gen.Gulf <- gen.net[keep.ind, ]
X.Gulf <- scaleGen(gen.Gulf, NA.method="mean", scale=F)

dbMEM_Gulf <- dbmem(gen.Gulf@other$lat, MEM.autocor="positive")
dim(dbMEM_Gulf)
#3 MEMs
par(mfrow=c(2,2))
for(i in 1:3){
ordisurf(gen.Gulf@other$lat[,1:2], dbMEM_Gulf[,i])
}

#Doing permutation selection
m1<-rda(X.Gulf ~ ., dbMEM_Gulf)
m0<-rda(X.Gulf ~ 1, dbMEM_Gulf)

m.ord_Gulf <- ordistep(m0, scope = formula(m1), Pin=0.05, Pout=0.10, permutations = how(nperm = 999))
{ #Results
Start: X.Gulf ~ 1

       Df    AIC      F Pr(>F)
+ MEM1  1 320.45 1.1889  0.002 **
+ MEM3  1 320.60 1.0398  0.024 *
+ MEM2  1 320.62 1.0151  0.238
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Step: X.Gulf ~ MEM1

       Df    AIC      F Pr(>F)
- MEM1  1 319.67 1.1889  0.002 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

       Df    AIC      F Pr(>F)
+ MEM3  1 321.34 1.0444  0.052 .
+ MEM2  1 321.37 1.0196  0.318
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
}

m.ord_Gulf
{ #Results
Call: rda(formula = X.Gulf ~ MEM1, data = dbMEM_Gulf)

                Inertia Proportion Rank
Total         1190.1956     1.0000
Constrained     32.0214     0.0269    1
Unconstrained 1158.1742     0.9731   43
Inertia is variance

Eigenvalues for constrained axes:
 RDA1
32.02

Eigenvalues for unconstrained axes:
   PC1    PC2    PC3    PC4    PC5    PC6    PC7    PC8
31.151 30.638 30.465 30.230 30.130 29.819 29.427 29.394
(Showing 8 of 43 unconstrained eigenvalues)
}
#MEM 1 is an East/West gradient
#MEM 2 is also an East/West gradient
#MEM 3 is also an East/West gradient, but with N/S variation in the middle

#Preparinig the contours for mapping
#dbMEM[,1]
ordi <- ordisurf(gen.net@other$lat[,1:2], dbMEM[,1], plot = FALSE)
ordi.grid <- ordi$grid
ordi.data <- expand.grid(x = ordi.grid$x, y = ordi.grid$y)
ordi.data$z <- as.vector(ordi.grid$z)
df_surf <- data.frame(na.omit(ordi.data))
r <- range(dbMEM[,1])
binwidth <- (r[2] - r[1])/15
#dbMEM_Gulf[,1]
ordi <- ordisurf(gen.Gulf@other$lat[,1:2], dbMEM_Gulf[,1], plot = FALSE)
ordi.grid <- ordi$grid
ordi.data <- expand.grid(x = ordi.grid$x, y = ordi.grid$y)
ordi.data$z <- as.vector(ordi.grid$z)
df_surf_Gulf <- data.frame(na.omit(ordi.data))
r <- range(dbMEM_Gulf[,1])
binwidth_Gulf <- (r[2] - r[1])/15

#Gulf map
Gulf_map<-ggmap(get_stamenmap(bbox = c(left = -100, bottom = 24, right =-74, top = 38.3), zoom = 8, maptype=c("terrain-background")))
Gulf_map

#All samples MEM
p.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat), data=gen.net@other$lat, shape=19, color="black", size =2.5) + ggtitle("Significant distance based contours between samples") + 
	stat_contour(data = df_surf,aes(x = x, y = y, z = z, color = ..level..), binwidth = binwidth) + labs(color = "Level") + coord_fixed(ratio = 1) + 
	scale_color_gradient(low="violetred1", high="black")
p.map

#Gulf samples MEM
p_Gulf.map<-Gulf_map + geom_point(aes(x = Lon, y = Lat), data=gen.Gulf@other$lat, shape=19, color="black", size =2.5) + ggtitle("Significant distance based contours between Gulf samples") + 
	stat_contour(data = df_surf_Gulf,aes(x = x, y = y, z = z, color = ..level..), binwidth = binwidth_Gulf)+ labs(color = "Level") + coord_fixed(ratio = 1) + 
	scale_color_gradient(low="black", high="violetred1")
p_Gulf.map

multiplot(p.map, p_Gulf.map, cols=1)
ggsave("dbMEM_maps.tiff", multiplot(p.map, p_Gulf.map, cols=1), device="tiff")

#Plotting the RDAs
#Setting colors
col_rda <- as.character(gen.net@strata$G3)
col_rda <- gsub("1", "dodgerblue", col_rda)
col_rda <- gsub("2", "red4", col_rda)
col_rda <- gsub("3", "mediumblue", col_rda)

col_rda_Gulf <- as.character(gen.Gulf@strata$G3)
col_rda_Gulf <- gsub("1", "chocolate", col_rda_Gulf)
col_rda_Gulf <- gsub("3", "mediumblue", col_rda_Gulf)

#Getting variation
var.net <- round((c(m.ord$CCA$eig, m.ord$CA$eig)/sum(m.ord$CCA$eig, m.ord$CA$eig))*100,3)
var.Gulf <- round((c(m.ord_Gulf$CCA$eig, m.ord_Gulf$CA$eig)/sum(m.ord_Gulf$CCA$eig, m.ord_Gulf$CA$eig))*100,3)

#Writing out plots
tiff("RDA_scatter_dbMEM.tiff",res=300, width=3000, height=6000)
par(mfrow=c(2,1))
plot(m.ord)
points(m.ord, display = "sites", bg=col_rda, pch=21, col="black")
legend(-8.1,-1, pt.bg=c3[c(2,1,3)], legend=c("Atlantic", "East GOM", "West GOM"), pch=21, bty="n", col="black")
mtext("All Samples", 3)
mtext(paste("RDA1 = ", var.net["RDA1"], "%", sep=""), 1, line=-3, adj=0.15)
mtext(paste(" PC1 = ", var.net["PC1"], "%", sep=""), 1, line=-2, adj=0.15)

plot(m.ord_Gulf)
points(m.ord_Gulf, display = "sites", bg=col_rda_Gulf, pch=21, col="black")
legend(-10.7,-2, pt.bg=c("chocolate","mediumblue"), legend=c("East GOM", "West GOM"), pch=21, bty="n", col="black")
mtext("Gulf Samples", 3, line=0)
mtext(paste("RDA1 = ", var.Gulf["RDA1"], "%", sep=""), 1, line=-3, adj=0.15)
mtext(paste(" PC1 = ", var.Gulf["PC1"], "%", sep=""), 1, line=-2, adj=0.15)
dev.off()


#Exporting data
{```{R}```
setPop(gen.net)<-~G3
writeGenPop(gen.net, "SNP.TRS.Final_neutral.gen", "Neutral Angel sharks data without dups by POP")
}

#External Analysis
{```{bash}```
`# Arlequin #`
#Converting to Arlequin format
{```{bash}```
java -jar /usr/local/bin/PGDSpider2.1.1.3-cli.jar -inputfile SNP.TRS.Final_neutral.gen -inputformat GENEPOP -outputfile SNP.TRS.Final_neutral.arp -outputformat Arlequin -spid ~/bin/genepop_to_arlequin_STD.spid
#Add Structure part and change pop names
nano SNP.TRS.Final_all.arp
#Import arl_run_Global.ars from Arlequin on PC where it was saved using the arp file to get the parameters right
#Turn off XLM so that you can view it in a web browser

#Run Global AMOVA
arlecore3522_64bit SNP.TRS.Final_all.arp arl_run_Global.ars
#Change the structure
nano SNP.TRS.Final_all.arp
#Run Hierarchical AMOVA
arlecore3522_64bit SNP.TRS.Final_all.arp arl_run_Global.ars
}

`# Structure analysis #`
{```{R}```
##from Andrew Kinziger http://lists.r-forge.r-project.org/pipermail/adegenet-forum/2010-April/000099.html##
#CONVERSION OF GENIND OBJECT TO LOCI OBJECT
setPop(gen.net)<-~G3
x <- as.loci(gen.net)
#WRITE STRUCTURE file
write.loci(x, file = "SNP.TRS.Final_neutral.structure", loci.sep ="\t", quote = FALSE, allele.sep ="\t", na ="-9\t-9", col.names = FALSE)
}

{```{bash}```
#Make structure file way 1
cut -f2- SNP.TRS.Final_neutral.structure > SNP.TRS.Final_neutral.structure2

#Make structure file way 2
awk '{$2=""; print}' SNP.TRS.Final_neutral.structure | sed 's/  / /' > SNP.TRS.Final_neutral.structure3
}

{```{bash}```
#Test to make sure that it runs
mkdir -p structure/k3
cd structure/k3
VAR=3; i=1; RAND=1234; time structure -i ../../SNP.TRS.Final_neutral.structure2 -m ../mainparams -e ../extraparams -K $VAR -D $RAND -o /home/afields/Workspace/Angels/analysis/Aug2020/structure/k3_v2/SNP.TRS.Final_neutral.K$VAR.R$i > log.R$i

#Do this for each value of k to test (example for K=4)
VAR=3;for i in {1..10}; do RAND=$(echo "1234*$i" | bc); time structure -i ../../SNP.TRS.Final_neutral.structure2 -m ../mainparams -e ../extraparams -K $VAR -SEED $RAND -o ../../SNP.TRS.Final_neutral.K$VAR.R$i > log.R$i & done
}
}

`# DIYABC analysis #`
#Getting mutation models
#Getting data
cd /home/afields/Workspace/Angels/analysis/Aug2020
mkdir mut_models
cd mut_models
mkdir logs mods
bgzip -c ../haplotyping/SNP.TRS.F10.vcf > SNP.TRS.F10.vcf.gz
tabix -fp vcf SNP.TRS.F10.vcf.gz
cp -s ../../../mapping/reference.fasta* .
python3 /usr/local/bin/seq_length.py reference.fasta > ref.length
grep dDocent SNP.TRS.F10.vcf | grep -v "#" | cut -f1 | sort -u > contigs

#Running script

#Running jmodeltest on first 1000 contigs
rm mod.log
cat contigs | head -n1000 | while read i; do
echo $i >> mod.log
LEN=$(grep $i ref.length | cut -f2)
LEN2=$(echo $LEN"-1" | bc)
python ~/bin/alignment-from-vcf.py reference.fasta SNP.TRS.F10.vcf.gz $i 2 $LEN2 2 out.fasta
java -jar /usr/local/bin/jmodeltest-2.1.10/jModelTest.jar -d out.fasta -getPhylip
sed -i 's/[.]/_/g' out.fasta.phy
java -jar /usr/local/bin/jmodeltest-2.1.10/jModelTest.jar -AIC -AICc -BIC -DT -d out.fasta.phy -hLRT -i -f -g 4 -S BEST -t ML -tr 16 -p -a -o mods/${i}_output.txt >> mod.log
done

#Loop over all the contigs to get the model for each
echo -e "dDocent_Contig_13023\ndDocent_Contig_13024" | while read i; do
echo $i >> mod.log
LEN=$(grep $i ref.length | cut -f2)
LEN2=$(echo $LEN"-1" | bc)
python ~/bin/alignment-from-vcf.py reference.fasta SNP.TRS.F10.vcf.gz $i 2 $LEN2 2 out.fasta
java -jar /usr/local/bin/jmodeltest-2.1.10/jModelTest.jar -d out.fasta -getPhylip
sed -i 's/[.]/_/g' out.fasta.phy
java -jar /usr/local/bin/jmodeltest-2.1.10/jModelTest.jar -AIC -AICc -BIC -DT -d out.fasta.phy -hLRT -i -f -g 4 -S BEST -t ML -tr 16 -p -a -o mods/${i}_output.txt >> mod.log
done

#Looking at how many models are done
ls mods/*_output.txt | wc -l

#Parsing mutation models
#Remove old data
if [ -a Mut_model.txt ] ; then rm Mut_model.txt; fi

cat contigs | head -n1000 | while read i; do
if [ $(ls mods/${i}_output.txt | wc -l) -eq 0 ] ; then echo "$i jmodeltest results missing" | tee mut.log; continue; fi;
grep delta -A11 mods/${i}_output.txt | grep Model -A11 | sed '/--/d' > tmp.file
if [ $(wc -l tmp.file | cut -f1 -d " ") -lt 44 ] ; then echo "Check $i jmodeltest results" | tee mut.log; continue; fi
Rscript ~/bin/Model_analysis.r
rm tmp.file
done

sort Mut_model.txt | uniq -c
{#Results
    389 F81
      9 F81+I
     22 HKY
      1 HKY+G
      5 HKY+I
    519 JC
      1 JC+G
     16 JC+I
     22 K80
      4 K80+G
     12 K80+I
}

#Alt way of looking at the data
```{R}```
dat <- read.table("Mut_model.txt", head=F)
table(dat)

```{bash}```
cat contigs | head -n1000 > contigs.sub
paste contigs.sub Mut_model.txt > Final_Models.txt




```{R}```
#Rank_analysis.r

#!/bin/Rscript
dat <- read.table("tmp.file", head=T, fill=T)
dat$Rank <- c(rep(seq(1,11), 3), seq(1,10))

tmp.MODEL <- unique(as.character(as.matrix(dat$Model)))
MODELS <- data.frame(matrix(ncol=1, nrow=length(tmp.MODEL)), row.names=tmp.MODEL)
names(MODELS) <- "Rank"

for(i in rownames(MODELS)){
tmp.rank <- dat[dat$Model==i,"Rank"]
MODELS[rownames(MODELS)==i,1] <- mean(head(c(tmp.rank,rep(11,4)),4))
}

TOP <- rownames(MODELS)[min(MODELS$Rank)==MODELS$Rank]

if(length(TOP)>1){
tie_breaker <- vector()
for(i in TOP){
tmp.delta <- as.numeric(as.matrix(dat[dat$Model==i,"delta"]))
tie_breaker <- c(tie_breaker,mean(head(c(tmp.delta,rep(11,4)),4)))
}
}

TOP <- TOP[min(tie_breaker)==tie_breaker]

write.table(TOP, "Mut_model.txt", append=T, col.names=F, row.names=F, quote=F)

#Getting genepop data for analysis##


#Getting haplotype sequences for analysis##
```{R}```
#Read in the sequence data
seqs <- read.table("haplotyping/codes.SNP.TRS.F10.gen", head=F)
seqs <- seqs[seqs$V1 %in% locNames(gen.net),]

#Define variables
indv <- indNames(gen.net)
loci <- as.character(seqs[,1])

#Make a list as long as the number of loci
seq.list <- vector("list",nrow(seqs))

#Pull the allele number and varible DNA sequences for each locus
for(i in 1:nrow(seqs)){
seqs2 <- data.frame(matrix(unlist(strsplit(as.character(gsub(":", ",", seqs[i,2])),",")),ncol=2, byrow=T))
colnames(seqs2) <- c("Seq", "Allele")
seq.list[[i]] <- seqs2
}
seq.list <- setNames(seq.list, as.character(seqs[,1]))

#Make the final data table
final <- matrix(nrow=length(indv), ncol=2*length(loci))
rownames(final)<-indNames(gen.net)
colnames(final)<-rep(locNames(gen.net), each=2)

#Fill in the final table
rm.loci <- vector()
for(j in loci){
geno <- gen.net@tab[ , grep(paste(j,".",sep=""),colnames(gen.net@tab), fixed=T)]
if(class(geno)=="integer"){final <- final[,-(grep(j,colnames(final)))]; print(paste("Locus", j, "removed because it is monomorphic")); rm.loci <- c(rm.loci,j); next}
colnames(geno) <- gsub(paste(j,".",sep=""), "", colnames(geno))
print(paste("processing locus", j))
for(i in indv){
if(sum(is.na(geno[rownames(geno)==i,]))>0){next}
tmp <- geno[rownames(geno)==i,]
tmp <- tmp[tmp > 0]
if(length(tmp) == 1){final[rownames(final)==i,colnames(final)==j] <- rep(as.character(seq.list[[j]][seq.list[[j]][,2]==names(tmp),1]),2)
} else if(length(tmp) == 2){a <- as.character(seq.list[[j]][seq.list[[j]][,2]==names(tmp)[1],1])
b<-as.character(seq.list[[j]][seq.list[[j]][,2]==names(tmp)[2],1])
final[rownames(final)==i,colnames(final)==j] <- c(a,b)}
}}

#Redefining loci
loci.end <- unique(colnames(final))

#Define populations
setPop(gen.net)<-~G3
table(pop(gen.net), gen.net@strata$POP)
EAST <- indNames(gen.net)[pop(gen.net)==1]
ATL <- indNames(gen.net)[pop(gen.net)==2]
WEST <- indNames(gen.net)[pop(gen.net)==3]

write.table(final[rownames(final) %in% WEST,],"WEST_haplotypes.txt", sep="\t", quote=F, col.names=F, row.names=T)
write.table(final[rownames(final) %in% EAST,],"EAST_haplotypes.txt", sep="\t", quote=F, col.names=F, row.names=T)
write.table(final[rownames(final) %in% ATL,],"ATL_haplotypes.txt", sep="\t", quote=F, col.names=F, row.names=T)
write.table(loci.end, "loci.txt", row.names=F, col.names=F, quote=F)

```{bash}```
echo "Angel Shark DIYABC by KMEANS < NM = 1.0NF >" > DIYABC.file
awk 'BEGIN{OFS="\t"}{print $0, "<A>"}' loci.txt >> DIYABC.file
echo "Pop" >> DIYABC.file
awk '{for (i = 2; i <= NF; i=i+2) print "<["$i"]["$(i+1)"]> ";}' WEST_haplotypes.txt > WEST.tmp

for i in $(seq 1 $(wc -l WEST_haplotypes.txt| cut -d " " -f 1)); do
echo $i
LOCI=$(wc -l loci.txt | cut -f1 -d" ")
TAIL=$(echo "$i*$LOCI" | bc)
head -n $TAIL WEST.tmp | tail -n $LOCI | sed -z 's:\n:\t:g' > tmp.geno
awk -v var=$i 'NR==var{print $1, ","}' WEST_haplotypes.txt > tmp.indv
cat tmp.indv tmp.geno | sed -z 's:\n:\t:g' >> DIYABC.file
done

echo -e "\nPop" >> DIYABC.file
awk '{for (i = 2; i <= NF; i=i+2) print "<["$i"]["$(i+1)"]> ";}' EAST_haplotypes.txt > EAST.tmp

for i in $(seq 1 $(wc -l EAST_haplotypes.txt| cut -d " " -f 1)); do
echo $i
LOCI=$(wc -l loci.txt | cut -f1 -d" ")
TAIL=$(echo "$i*$LOCI" | bc)
head -n $TAIL EAST.tmp | tail -n $LOCI | sed -z 's:\n:\t:g' > tmp.geno
awk -v var=$i 'NR==var{print $1, ","}' EAST_haplotypes.txt > tmp.indv
cat tmp.indv tmp.geno | sed -z 's:\n:\t:g' >> DIYABC.file
done

echo -e "\nPop" >> DIYABC.file
awk '{for (i = 2; i <= NF; i=i+2) print "<["$i"]["$(i+1)"]> ";}' ATL_haplotypes.txt > ATL.tmp

for i in $(seq 1 $(wc -l ATL_haplotypes.txt| cut -d " " -f 1)); do
echo $i
LOCI=$(wc -l loci.txt | cut -f1 -d" ")
TAIL=$(echo "$i*$LOCI" | bc)
head -n $TAIL ATL.tmp | tail -n $LOCI | sed -z 's:\n:\t:g' > tmp.geno
awk -v var=$i 'NR==var{print $1, ","}' ATL_haplotypes.txt > tmp.indv
cat tmp.indv tmp.geno | sed -z 's:\n:\t:g' >> DIYABC.file
done

#Had to put each sample on its own line
#Code below should correct this without doing it by hand
sed -i -e 's/> \tWEST/>\nWEST/g' DIYABC.file
sed -i -e 's/> \tEAST/>\nEAST/g' DIYABC.file
sed -i -e 's/> \tAtl/>\nAtl/g' DIYABC.file

sed -i 's/NA//g' DIYABC.file

# DIYABC.file is complete

scp DIYABC.file afields@deepthought.ad.tamucc.edu:/home/afields/Workspace/Angels/test_DIYABC.file



{```{R}```
#Selecting random SNPs from VCF file
vcf<-read.vcfR(file="haplotyping/SNP.TRS.F10.vcf")
contigs <- sort(unique(vcf@fix[,1]))
gen.vcf<-vcfR2genind(vcf)
strata <- read.csv(file = "SNP.TRS.F10.2020-09-25/indv.csv", header = TRUE)
strata(gen.vcf) <- strata[match(indNames(gen.vcf),strata$INDV),]
head(strata(gen.vcf))

gen <- read.genepop(file = "haplotyping/SNP.TRS.F10.gen", ncode=3L, quiet = FALSE)
strata(gen) <- strata[match(indNames(gen),strata$INDV),]
head(strata(gen))

remove.ind <- c("Atl.AS.124_Lib1_I12_D05", "EAST.AS.9.2_Lib1_I12_D04", "Pac.AS.T437_Lib2_I12_D01")
set.ind <- subset(indNames(gen), !indNames(gen) %in% remove.ind)

gen2 <- gen[set.ind, ]
loc2 <- gen2@other$lat

gen2.vcf <- gen.vcf[set.ind, ]

OF.out <- read.table("Outflank_Library_Outliers.list", head=F)
tmp.out <- read.csv("Bayescan/Bayescan_Outliers_Lib.list", head=F)
gen.out.list <- unique(c(as.character(as.matrix(OF.out)), as.character(as.matrix(tmp.out))))
set.loc<-locNames(gen2)[which(!(locNames(gen2) %in% gen.out.list))]
gen3<-gen2[, loc=set.loc]
loc3<-gen3@other$lat

tmp<-vector()
for(i in gen.out.list){
tmp <- append(tmp,grep(i, locNames(gen2.vcf), fixed=F, value=T))
}

set.loc<-subset(locNames(gen2.vcf), !locNames(gen2.vcf) %in% tmp)
gen3.vcf<-gen2.vcf[ ,loc=set.loc]


loc.net <- locNames(gen3.vcf)
loc.net.df <- data.frame(matrix(unlist(strsplit(loc.net,"_")), byrow=T, ncol=4))
colnames(loc.net.df) <- c("dDocent", "Contig", "Locus", "Site")
loc.net.df$Names <- paste(loc.net.df$dDocent,loc.net.df$Contig,loc.net.df$Locus,sep="_")
loc.net.df <- loc.net.df[order(loc.net.df$Locus),]
loc.net2 <- unique(locNames(gen3))

diy_loci <- data.frame()
for(i in loc.net2){
a <- dim(loc.net.df[loc.net.df$Names == i, ])[1]
tmp <- sample(a,1)
diy_loci <- rbind(diy_loci, loc.net.df[loc.net.df$Names == i, ][tmp,])
}
head(diy_loci[,c("Names","Site")])
write.table(diy_loci[,c("Names","Site")], "DIYABC_Loci.txt", quote=F, row.names=F, col.names=F)

```{bash}```
vcftools --vcf haplotyping/SNP.TRS.F10.vcf --recode --recode-INFO-all --out SNP.TRS.F10.sub --positions DIYABC_Loci.txt --remove-indv Atl.AS.124_Lib1_I12_D05 --remove-indv EAST.AS.9.2_Lib1_I12_D04 --remove-indv Pac.AS.T437_Lib2_I12_D01

```{R}```
library('adegenet')
library('vcfR')
vcf<-read.vcfR(file="SNP.TRS.F10.sub.recode.vcf")
gen.vcf<-vcfR2genind(vcf)
strata <- read.csv(file = "SNP.TRS.F10.2020-09-25/indv.csv", header = TRUE)
strata(gen.vcf) <- strata[match(indNames(gen.vcf),strata$INDV),]
head(strata(gen.vcf))

gen.df <- genind2df(gen.vcf)
gen.df <- gen.df[-c(1)]
for(j in 1:ncol(gen.df)){gen.df[ ,j] <- as.numeric(as.character(gen.df[ ,j])) }

gen.df2 <- replace(gen.df, c(gen.df==00, gen.df=="00"), "AA")
gen.df2 <- replace(gen.df2, c(gen.df2==1, gen.df2==10, gen.df2=="01", gen.df2=="10"), "AC")
gen.df2 <- replace(gen.df2, c(gen.df2==11, gen.df2=="11"), "CC")
gen.df2 <- replace(gen.df2, c(gen.df2==2, gen.df2==20, gen.df2=="02", gen.df2=="20"), "AG")
gen.df2 <- replace(gen.df2, c(gen.df2==12, gen.df2==21, gen.df2=="12", gen.df2=="21"), "CG")
gen.df2 <- replace(gen.df2, c(gen.df2==22, gen.df2=="22"), "GG")

gen.df2 <- replace(gen.df, "00", "AA")
gen.df2 <- replace(gen.df2, gen.df2=="01", "AC")
gen.df2 <- replace(gen.df2, gen.df2=="10", "AC")
gen.df2 <- replace(gen.df2, gen.df2=="11", "CC")
gen.df2 <- replace(gen.df2, gen.df2=="02", "AG")
gen.df2 <- replace(gen.df2, gen.df2=="20", "AG")
gen.df2 <- replace(gen.df2, gen.df2=="12", "CG")
gen.df2 <- replace(gen.df2, gen.df2=="21", "CG")
gen.df2 <- replace(gen.df2, gen.df2=="22", "GG")

table(as.matrix(gen.df2))

write.table(gen.df2, file="gen.df2", quote=F, col.names=T, row.names=T)

```{bash}```
#Put data into a temporary directory
mkdir tmp
cp gen.df2 tmp
cd tmp

#Make a file of the loci
head -n1 gen.df2 > contigs
#Make a file of the samples
tail -n+2 gen.df2 | cut -d" " -f1 > samples
#Make a file of the genotypes without row names or headers
tail -n+2 gen.df2 | cut -d" " -f2- > genos

#Make an extra row on the geno file
cut -d" " -f1 genos > extra
paste -d" " genos extra > tmp_geno
#put a / between each of the bases and remove the extra row
sed 's:. :\/& :g' tmp_geno | awk 'NF{NF-=1};1' > geno_new
#Add the sample names (row names)
paste -d" " samples geno_new > tmp1
#Add the loci names (column names)
cat contigs tmp1 > gen.df3

#move the file and remove the intermediate steps
cp gen.df3 ../
cd ..
rm -r tmp

```{bash}```
vcftools --vcf SNP.TRS.F06.sub.recode.vcf --out tmp --012
vcfsitesummarize SNP.TRS.F06.sub.recode.vcf | cut -f1 > contigs

#{r_val.sh}
#!/bin/bash
#Usage: r_val.sh <VCF filename> <# of splits/processors> <output file name>
if [[ -z "$3" ]]; then echo "Usage: r_val.sh <VCF filename> <# of splits/processors> <output file name>"; fi
#Define varibles
FILE=$1
SPLIT=$2
OUT=$3

#Making necessary files
vcftools --vcf $FILE --out tmp --012
vcfsitesummarize $FILE | cut -f1 > contigs

#Preparing temporary folders
for i in $(seq 1 $SPLIT); do 
mkdir tmp_$i
cd tmp_$i
cp -s ../contigs ../tmp.012 .
cd ..
done

for i in $(seq 1 $SPLIT); do 
cd tmp_$i
LD_loop.sh $SPLIT $i
cd .. & done
wait

#Creating output
rm $OUT
touch $OUT
for i in $(seq 1 $SPLIT); do 
cat tmp_$i/tmp.out >> $OUT
done

##END##

#LD_loop.sh
#!/bin/bash
#Usage: Used in LD_loop.sh
if [[ -z "$2" ]]; then echo "Usage: LD_loop.sh <# of splits/processors> <directory number>"; fi
#Define varibles
SPLIT=$1
DIR=$2

#Defining conditional varibles
LENGTH=$(awk 'NR==1{print NF-1}' tmp.012)
COMP=$(echo "($LENGTH*($LENGTH-1))/2" | bc)
PART=$(echo "$COMP/$SPLIT" | bc)

#Defining varibles
if [[ "$DIR" == 1 ]]; then START=3
elif [[ "$DIR" > 1 ]]; then START=$(echo "($LENGTH - sqrt($LENGTH^2 - 2*$PART*($DIR-1)))+2" | bc)
fi

if [[ "$DIR" < "$SPLIT" ]]; then END=$(echo "$LENGTH - sqrt($LENGTH^2 - 2*$PART*($DIR))+1" | bc)
elif [[ "$DIR" == "$SPLIT" ]]; then END=$LENGTH
fi

#Preparing output file
echo "Locus_1 Locus_2 r_RH r_ES" > tmp.out

for j in $(seq 2 $LENGTH); do 
echo $j
for k in $(seq $START $END); do 
if [[ "$j" > "$k" ||  "$j" == "$k" ]]; then continue; fi
cut -f$j,$k tmp.012 | grep -v -e "-1" > tmp
r_value=$(python ~/programs/covld/covld.py -es tmp | awk '{a[NR]=$2} END{print a[2], a[3]}')
LOCUS1=$(head -n $j contigs | tail -n 1)
LOCUS2=$(head -n $k contigs | tail -n 1)
echo $LOCUS1 $LOCUS2 $r_value > tmp.out
done; done

##END##
}


#Getting PopGenReport
{```{R}```
library('PopGenReport')
library('tinytex')
gen.net@other$xy<-gen.net@other$lat
report.test <- popgenreport(gen.net, mk.counts=T, mk.pdf=T, foldername="report")
#Total allele counts and allelic richness

gen.hf <- genind2hierfstat(gen.net)
tmp.v <- as.character(as.matrix(gen.hf[,1]))
tmp.v[tmp.v=="1"] <- "EGOM"
tmp.v[tmp.v=="2"] <- "Atl"
tmp.v[tmp.v=="3"] <- "WGOM"
gen.hf[,1] <- as.factor(tmp.v)

allelic.richness(gen.hf)
}

for (i in sort(unique(gen.hf[, 1]))) {
        dum <- 1:sum(gen.hf[, 1] == i)
        if (i == 1)
            ind <- dum
        else ind <- c(ind, dum)
    }
data.al <- data.frame(pop = rep(gen.hf[, 1], 2), ind = ind, al = rbind(firstal, secal))



{#Extras
table(xval.2.net$DAPC$assign, grp2$grp)
table(xval.3.net$DAPC$assign, grp3$grp)
table(xval.4.net$DAPC$assign, grp4$grp)
table(xval.5.net$DAPC$assign, grp5$grp)
table(xval.6.net$DAPC$assign, grp6$grp)
table(xval.7.net$DAPC$assign, grp7$grp)

par(mfrow=c(3,1))
ade4::s.class(pca.net$li, as.factor(gen.net@strata$G2), col=c("blue", "red4"), cstar=0)
mtext("Neutral data K-means=2", 3, 2, adj = 0.95)
ade4::s.class(pca.net$li, as.factor(gen.net@strata$G3), col=c("blue", "red4", "green"), cstar=0)
mtext("Neutral data K-means=3", 3, 2, adj = 0.95)
ade4::s.class(pca.net$li, as.factor(gen.net@strata$G4), col=c("blue", "red4", "green", "orange"), cstar=0)
mtext("Neutral data K-means=4", 3, 2, adj = 0.95)
}
}

`# Script parts which could become functions #`
#Plotting the frequency of each allele for the loci contributing to a DAPC axis
{```{R}```
#Get contributing loci
contrib <- loadingplot(xval.3.net$DAPC$var.contr, axis=1, thres=.0009, lab.jitter=1)
pc.loci <- unique(matrix(unlist(strsplit(contrib$var.names, "[.]")),ncol=2,byrow=T)[,1])

#Extra libraries
library('RColorBrewer')
#Set the color
#Note Accent only has 8 colors so another palette might be desired
#Can  set own scheme just by defining col.plot to desired colors
#col.plot <- brewer.pal(length(levels(pop(gen.net))), "Accent")
col.plot <- c("red4", "dodgerblue", "mediumblue")

#Setting the plots grid
x.dim <- ceiling(sqrt(length(pc.loci)))
y.dim <- ceiling(length(pc.loci)/x.dim)
par(mfrow=c(y.dim,x.dim))

#Define the population

setPop(gen.net) <- ~POP

#Getting the data and plotting each locus
for(i in pc.loci){
#Get locus data
tmp.dat <- cbind(gen.net@tab[,grep(i, colnames(gen.net@tab))],as.character(pop(gen.net)))
tmp.dat <- data.frame(tmp.dat[,order(colnames(tmp.dat))])

#Make certain data is numeric
for(j in 2:ncol(tmp.dat)){tmp.dat[,j] <- as.numeric(as.matrix(tmp.dat[,j]))}

#Making the data into percents
plot.dat <- data.frame(matrix(ncol=length(table(tmp.dat[,1])), nrow=(ncol(tmp.dat)-1)))
colnames(plot.dat) <- names(table(tmp.dat[,1]))
for(j in names(table(tmp.dat[,1]))){
plot.dat[,j] <- (apply(tmp.dat[tmp.dat[,1]==j,2:ncol(tmp.dat)], 2, function(x) sum(x, na.rm=T))/sum(tmp.dat[tmp.dat[,1]==j,2:ncol(tmp.dat)], na.rm=T))*100
}

#Adding haplotype names
h.name <- "H1"
for(j in 2:(ncol(tmp.dat)-1)){h.name <- c(h.name, paste("H",j,sep=""))}

#Plotting the locus
if(tail(pc.loci,1)==i){barplot(as.matrix(t(plot.dat)), beside=T, col=col.plot, main=i, legend.text=names(plot.dat), names.arg=h.name, ylab="Percent")
} else {barplot(as.matrix(t(plot.dat)), beside=T, col=col.plot, main=i, names.arg=h.name, ylab="Percent")
}
}

}}}}}}}}}}}}}}}} #Cleanup

#Comparing Fis and Position in the haplotype network
{```{R}```
#Load data 
dat <- data.frame(
Hap=c("2","1","1","1","1","1","1","2","1","1","1","1","1","1","1","3","1","1","1","3","3","1","1","1","2","1","1","1","1","1","3","3","3","3","3","3","3","3","3","3","3","3","3","3","3","3"), 
Fis=c("-0.02441","0.04378","0.01145","0.0341","0.06045","-0.02781","-0.05922","-0.00254","0.03328","-0.00704","-0.04246","-0.03518","-0.05223","-0.04643","-0.01992","0.02199","0.01221","-0.03329","-0.03294","-0.06689","-0.06345","0.05497","0.06008","0.06394","-0.11036","0.07869","0.05731","-0.05081","-0.07566","0.03301","0.06325","0.01076","-0.02074","-0.03841","0.00424","-0.03334","-0.10686","0.06262","0.04208","0.07313","0.06063","0.00846","-0.02794","0.03298","0.02732","0.06961"), 
G3=c("Atl","Atl","Atl","Atl","Atl","Atl","Atl","Atl","Atl","Atl","Atl","Atl","Atl","Atl","EAST","EAST","EAST","EAST","EAST","West","West","EAST","EAST","EAST","EAST","EAST","EAST","EAST","EAST","EAST","West","West","West","West","West","West","West","West","West","West","West","West","West","West","West","West"))

#Make sure Fis is numeric
dat$Fis <- as.numeric(as.matrix(dat$Fis))

#Make sure Hap is not numeric
class(dat$Hap)

#Plot
boxplot(Fis ~ Hap + G3, data=dat)

#There is no relationship here
